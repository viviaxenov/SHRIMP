{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "WIP ML potential with new DIFFERENTIABLE descriptors",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viviaxenov/SHRIMP/blob/main/WIP_ML_potential_with_new_DIFFERENTIABLE_descriptors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8ZH9ERvVzDF"
      },
      "source": [
        "Copyright 2019 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "     https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwAxXxabVmj"
      },
      "source": [
        "# Imports & Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVIHud2diL51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc4c95d-1c01-41b1-d322-18459deacb06"
      },
      "source": [
        "!pip install -q git+https://www.github.com/deepmind/haiku\n",
        "!pip install -q --upgrade git+https://www.github.com/google/jax-md\n",
        "\n",
        "# Imports\n",
        "\n",
        "import os\n",
        "import numpy as onp\n",
        "import pickle\n",
        "\n",
        "import jax\n",
        "from jax import lax\n",
        "\n",
        "from jax.api import jit, vmap, grad\n",
        "\n",
        "# TODO: Re-enable x64 mode after XLA bug fix.\n",
        "# from jax.config import config ; config.update('jax_enable_x64', True)\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import jax.numpy as np\n",
        "\n",
        "\n",
        "from jax import random\n",
        "\n",
        "from jax_md import energy, space, simulate, quantity\n",
        "\n",
        "# Plotting.\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "from functools import partial\n",
        "  \n",
        "sns.set_style(style='white')\n",
        "sns.set(font_scale=1.6)\n",
        "\n",
        "def format_plot(x, y):\n",
        "  plt.xlabel(x, fontsize=20)\n",
        "  plt.ylabel(y, fontsize=20)\n",
        "  \n",
        "def finalize_plot(shape=(1, 1)):\n",
        "  plt.gcf().set_facecolor('white')\n",
        "  plt.gcf().set_size_inches(\n",
        "    shape[0] * 1.5 * plt.gcf().get_size_inches()[1], \n",
        "    shape[1] * 1.5 * plt.gcf().get_size_inches()[1])\n",
        "  plt.tight_layout()\n",
        "\n",
        "def draw_training(params):\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(plt.gcf())\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.semilogy(train_energy_error)\n",
        "  plt.semilogy(test_energy_error)\n",
        "  plt.xlim([0, train_epochs])\n",
        "  format_plot('Epoch', '$L$')\n",
        "  plt.subplot(1, 2, 2)\n",
        "  predicted = vectorized_energy_fn(params, example_positions)\n",
        "  plt.plot(example_energies, predicted, 'o')\n",
        "  plt.plot(np.linspace(-400, -300, 10), np.linspace(-400, -300, 10), '--')\n",
        "  format_plot('$E_{label}$', '$E_{prediction}$')\n",
        "  finalize_plot((2, 1))\n",
        "  plt.show()\n",
        "\n",
        "# Data Loading.\n",
        "\n",
        "def MD_trajectory_reader(f, no_skip=20):\n",
        "  filename = os.path.join('Supplementary/', f)\n",
        "  fo = open(filename, 'r')\n",
        "  samples = fo.read().split('iter= ')[1:]\n",
        "  steps = []\n",
        "  lattice_vectors = []\n",
        "  positions = []\n",
        "  forces = []\n",
        "  temperatures = []\n",
        "  energies = []\n",
        "  for sample in samples[::no_skip]:\n",
        "    entries = sample.split('\\n')\n",
        "    steps.append(int(entries[0]))\n",
        "    lattice_vectors.append(onp.array([list(map(float, lv.split())) for lv in entries[1:4]]))\n",
        "    assert entries[4]=='64'\n",
        "    temp = onp.array([list(map(float, lv.split()[1:])) for lv in entries[5:69]])\n",
        "    positions.append(temp[:,:3])\n",
        "    forces.append(temp[:,3:])\n",
        "    remaining_lines = entries[69:]\n",
        "    temperatures.append(float([entry for entry in entries[69:] if 'Temp' in entry ][0].split('=')[1].split()[0]))\n",
        "    energies.append(float([entry for entry in entries[69:] if 'el-ion E' in entry ][0].split('=')[1].split()[0]))\n",
        "  assert (len(set(steps))-(steps[-1]-steps[0]+1)/no_skip) < 1\n",
        "  return np.array(positions), np.array(energies), np.array(forces)\n",
        "\n",
        "def build_dataset():\n",
        "  no_skip = 15\n",
        "  data300, energies300, forces300 = MD_trajectory_reader(\n",
        "      'MD_DATA.cubic_300K', no_skip=no_skip)\n",
        "  data600, energies600, forces600 = MD_trajectory_reader(\n",
        "      'MD_DATA.cubic_600K', no_skip=no_skip)\n",
        "  data900, energies900, forces900 = MD_trajectory_reader(\n",
        "      'MD_DATA.cubic_900K', no_skip=no_skip)\n",
        "  dataliq, energiesliq, forcesliq = MD_trajectory_reader(\n",
        "      'MD_DATA.liq_1', no_skip=no_skip)\n",
        "\n",
        "  all_data = np.vstack((data300, data600, data900))\n",
        "  all_energies = np.hstack((energies300, energies600, energies900))\n",
        "  all_forces = np.vstack((forces300, forces600, forces900))\n",
        "  noTotal = all_data.shape[0]\n",
        "\n",
        "  onp.random.seed(0)\n",
        "  II = onp.random.permutation(range(noTotal))\n",
        "  all_data = all_data[II]\n",
        "  all_energies = all_energies[II]\n",
        "  all_forces = all_forces[II]\n",
        "  noTr = int(noTotal * 0.65)\n",
        "  noTe = noTotal - noTr\n",
        "  train_data = all_data[:noTr]\n",
        "  test_data = all_data[noTr:]\n",
        "\n",
        "  train_energies = all_energies[:noTr]\n",
        "  test_energies = all_energies[noTr:]\n",
        "\n",
        "  train_forces = all_forces[:noTr]\n",
        "  test_forces = all_forces[noTr:]\n",
        "\n",
        "  return ((train_data, train_energies, train_forces),\n",
        "          (test_data, test_energies, test_forces))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jax-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPqQYKAtMp9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d3f554-903c-4886-a003-cbda4086bc38"
      },
      "source": [
        "!pip install -q git+https://www.github.com/google/jax-md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for jax-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZaB2_xGa-ye"
      },
      "source": [
        "import time \n",
        "\n",
        "from functools import partial\n",
        "import numpy as onp\n",
        "\n",
        "import jax.numpy as np\n",
        "\n",
        "from jax.api import jit\n",
        "from jax.api import grad\n",
        "from jax.api import vmap\n",
        "from jax.api import value_and_grad\n",
        "\n",
        "from jax import random\n",
        "from jax import lax\n",
        "\n",
        "from jax.experimental import stax\n",
        "from jax.experimental import optimizers\n",
        "\n",
        "from jax.config import config\n",
        "config.update('jax_enable_x64', True)\n",
        "\n",
        "from jax_md import space\n",
        "from jax_md import minimize\n",
        "from jax_md import simulate\n",
        "from jax_md import space\n",
        "from jax_md import energy\n",
        "from jax_md import quantity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmXjyeS780S2"
      },
      "source": [
        "# NOTE(schsam): We need this in OSS I think.\n",
        "from IPython.display import HTML, display\n",
        "import time\n",
        "\n",
        "def ProgressIter(iter_fun, iter_len=0):\n",
        "  if not iter_len:\n",
        "    iter_len = len(iter_fun)\n",
        "  out = display(progress(0, iter_len), display_id=True)\n",
        "  for i, it in enumerate(iter_fun):\n",
        "    yield it\n",
        "    out.update(progress(i + 1, iter_len))\n",
        "\n",
        "def progress(value, max):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 45%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbUxEQ69fSZ7"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "  \n",
        "sns.set_style(style='white')\n",
        "sns.set(font_scale=1.6)\n",
        "\n",
        "def format_plot(x, y):  \n",
        "  plt.xlabel(x, fontsize=20)\n",
        "  plt.ylabel(y, fontsize=20)\n",
        "  \n",
        "def finalize_plot(shape=(1, 1)):\n",
        "  plt.gcf().set_size_inches(\n",
        "    shape[0] * 1.5 * plt.gcf().get_size_inches()[1], \n",
        "    shape[1] * 1.5 * plt.gcf().get_size_inches()[1])\n",
        "  plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoRUeRrhdm1O"
      },
      "source": [
        "f32 = np.float32\n",
        "f64 = np.float64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xEERGYsdVNf"
      },
      "source": [
        "def box_size_at_number_density(particle_count, number_density):\n",
        "  return f32((particle_count / number_density) ** 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfBhUz0IiKN9"
      },
      "source": [
        "def pair_correlation_fun(dist_fun, cutoff=2.0, bin_count=60, sigma=None):\n",
        "  \"\"\"Calculates the pair correlation function for a collection of atoms.\"\"\"\n",
        "  if sigma is None:\n",
        "    sigma = cutoff / bin_count\n",
        "  bins = np.linspace(0.1, cutoff, bin_count)\n",
        "\n",
        "  dist_fun = vmap(vmap(dist_fun, (0, None)), (None, 0))\n",
        "\n",
        "  def compute(R):\n",
        "    # TODO(cubuk): Change this function to do batched calculation, as it can\n",
        "    # require too much memory for more than 1000 particles.\n",
        "    dr = dist_fun(R, R)\n",
        "    dr = np.where(dr > 1e-7, dr, 1e7)\n",
        "    dim = R.shape[1]\n",
        "    exp = np.exp(-0.5 * (dr[:, :, np.newaxis] - bins) ** 2 / sigma ** 2)\n",
        "    gaussian_distances = exp / np.sqrt(2 * np.pi * sigma ** 2)\n",
        "    return np.mean(gaussian_distances, axis=1) / bins ** (dim - 1)\n",
        "  return compute"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcmgyqSTtGKt"
      },
      "source": [
        "# Dataset download and preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMTGx696176Z",
        "outputId": "d24a18bf-991c-4b07-d943-4a08c89b99c2"
      },
      "source": [
        "#@title Download Data\n",
        "\n",
        "!wget https://aip.scitation.org/doi/suppl/10.1063/1.4990503/suppl_file/supplementary.zip\n",
        "!wget https://github.com/google/jax-md/blob/master/examples/models/si_gnn.pickle?raw=true\n",
        "!unzip supplementary.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-19 14:33:29--  https://aip.scitation.org/doi/suppl/10.1063/1.4990503/suppl_file/supplementary.zip\n",
            "Resolving aip.scitation.org (aip.scitation.org)... 104.17.164.62, 104.17.163.62\n",
            "Connecting to aip.scitation.org (aip.scitation.org)|104.17.164.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://aip.scitation.org/doi/suppl/10.1063/1.4990503/suppl_file/supplementary.zip?cookieSet=1 [following]\n",
            "--2021-03-19 14:33:30--  https://aip.scitation.org/doi/suppl/10.1063/1.4990503/suppl_file/supplementary.zip?cookieSet=1\n",
            "Reusing existing connection to aip.scitation.org:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://aip.scitation.org/doi/suppl/10.1063/1.4990503/suppl_file/supplementary.zip [following]\n",
            "--2021-03-19 14:33:30--  https://aip.scitation.org/doi/suppl/10.1063/1.4990503/suppl_file/supplementary.zip\n",
            "Reusing existing connection to aip.scitation.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 303986059 (290M) [application/zip]\n",
            "Saving to: ‘supplementary.zip’\n",
            "\n",
            "supplementary.zip   100%[===================>] 289.90M  17.0MB/s    in 16s     \n",
            "\n",
            "2021-03-19 14:33:46 (18.4 MB/s) - ‘supplementary.zip’ saved [303986059/303986059]\n",
            "\n",
            "--2021-03-19 14:33:46--  https://github.com/google/jax-md/blob/master/examples/models/si_gnn.pickle?raw=true\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/google/jax-md/raw/master/examples/models/si_gnn.pickle [following]\n",
            "--2021-03-19 14:33:46--  https://github.com/google/jax-md/raw/master/examples/models/si_gnn.pickle\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/google/jax-md/master/examples/models/si_gnn.pickle [following]\n",
            "--2021-03-19 14:33:47--  https://raw.githubusercontent.com/google/jax-md/master/examples/models/si_gnn.pickle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 780006 (762K) [application/octet-stream]\n",
            "Saving to: ‘si_gnn.pickle?raw=true’\n",
            "\n",
            "si_gnn.pickle?raw=t 100%[===================>] 761.72K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-03-19 14:33:47 (21.6 MB/s) - ‘si_gnn.pickle?raw=true’ saved [780006/780006]\n",
            "\n",
            "Archive:  supplementary.zip\n",
            "   creating: Supplementary/\n",
            "  inflating: Supplementary/MD_DATA.bSn_300K  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/Supplementary/\n",
            "  inflating: __MACOSX/Supplementary/._MD_DATA.bSn_300K  \n",
            "  inflating: Supplementary/MD_DATA.bSn_600K  \n",
            "  inflating: __MACOSX/Supplementary/._MD_DATA.bSn_600K  \n",
            "  inflating: Supplementary/MD_DATA.bSn_900K  \n",
            "  inflating: __MACOSX/Supplementary/._MD_DATA.bSn_900K  \n",
            "  inflating: Supplementary/MD_DATA.cubic_300K  \n",
            "  inflating: __MACOSX/Supplementary/._MD_DATA.cubic_300K  \n",
            "  inflating: Supplementary/MD_DATA.cubic_600K  \n",
            "  inflating: __MACOSX/Supplementary/._MD_DATA.cubic_600K  \n",
            "  inflating: Supplementary/MD_DATA.cubic_900K  \n",
            "  inflating: __MACOSX/Supplementary/._MD_DATA.cubic_900K  \n",
            "  inflating: Supplementary/MD_DATA.liq_1  \n",
            "  inflating: __MACOSX/Supplementary/._MD_DATA.liq_1  \n",
            "  inflating: Supplementary/MD_DATA.r8_300K  \n",
            "  inflating: __MACOSX/Supplementary/._MD_DATA.r8_300K  \n",
            "  inflating: Supplementary/MD_DATA.r8_600K  \n",
            "  inflating: __MACOSX/Supplementary/._MD_DATA.r8_600K  \n",
            "  inflating: Supplementary/MD_DATA.r8_900K  \n",
            "  inflating: __MACOSX/Supplementary/._MD_DATA.r8_900K  \n",
            "  inflating: Supplementary/NN_all_phases  \n",
            "  inflating: __MACOSX/Supplementary/._NN_all_phases  \n",
            "  inflating: __MACOSX/._Supplementary  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNIar1gB3zig",
        "outputId": "24dba0b7-8fa3-4de8-b310-b3a651cf046d"
      },
      "source": [
        "train, test = build_dataset()\n",
        "\n",
        "train_positions, train_energies, train_forces = train\n",
        "test_positions, test_energies, test_forces = test\n",
        "\n",
        "energy_mean = np.mean(train_energies)\n",
        "energy_std = np.std(train_energies)\n",
        "\n",
        "print('positions.shape = {}'.format(train_positions.shape))\n",
        "print('<E> = {}'.format(energy_mean))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positions.shape = (2416, 64, 3)\n",
            "<E> = -368.9131436758775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V6QV1Jvbe-9"
      },
      "source": [
        "# Machine Learned Potentials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hFCMBt_OS5-"
      },
      "source": [
        "## New descriptors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdIL6eHfshB8"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "\n",
        "import numpy as onp\n",
        "import numpy.polynomial as P\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "def get_assoc_legendre_coefs(l_max=10):\n",
        "  max_deg = P.legendre.leg2poly(onp.array([0]*(l_max)+[1.])).shape[0]\n",
        "  coefs = onp.zeros((l_max + 1, l_max + 1, max_deg))\n",
        "\n",
        "  for l in range(l_max + 1):\n",
        "    l_poly = P.Legendre(onp.array([0.]*(l)+[1.]))\n",
        "    for m in range(l + 1):\n",
        "      lm_poly = l_poly.deriv(m)\n",
        "      x_basis_coefs = P.legendre.leg2poly(lm_poly.coef)\n",
        "      deg = x_basis_coefs.shape[0]\n",
        "      coefs[l, m, :deg] = x_basis_coefs[::]\n",
        "\n",
        "  return coefs[:, :, ::-1]\n",
        "\n",
        "\n",
        "def get_normalization_coefs(l_max=10):\n",
        "  coefs = onp.zeros((l_max + 1, l_max + 1))\n",
        "  for l in range(l_max + 1):\n",
        "    for m in range(l + 1):\n",
        "      prod = onp.arange(l - m + 1, l + m + 1).prod()\n",
        "      coefs[l, m] = (-1)**m*onp.sqrt((2*l + 1)/4./onp.pi/prod)\n",
        "\n",
        "  return coefs\n",
        "\n",
        "\n",
        "def cartesian_to_spheric(x: np.array):\n",
        "  \"\"\"\n",
        "    Translates cartesian coords to spheric\n",
        "    Args:\n",
        "      x - [[x_1, x_2, x_3], ] array of coordinates\n",
        "  \"\"\"\n",
        "  x = np.atleast_2d(x)\n",
        "\n",
        "  r = np.linalg.norm(x, axis=1)\n",
        "  theta = np.arccos(x[:, 2]/r)\n",
        "  phi = np.arctan2(x[:, 1], x[:, 0])\n",
        "\n",
        "  return r, theta, phi\n",
        "\n",
        "\n",
        "def get_feature_evaluation_function(k_max=10, l_max=10, R=1.0, radial_comp_type='fourier'):\n",
        "  \n",
        "  # TODO: implement different types\n",
        "  if radial_comp_type != 'fourier':\n",
        "    raise NotImplementedError(\"Only fourier radial basis availiable at the moment\")\n",
        "\n",
        "  #ks = np.arange(-k_max, k_max + 1)\n",
        "  ls = np.arange(l_max + 1)\n",
        "  ms = np.arange(-l_max, l_max + 1)\n",
        "  ks = np.arange(-k_max, k_max +1)\n",
        "\n",
        "  def radial_comp_fourier(k, r):\n",
        "    arg = 2*np.pi*np.abs(k)*r/R\n",
        "    trig = np.where(k >= 0, np.cos(arg), np.sin(arg))\n",
        "    res = trig/np.sqrt(R)/r\n",
        "    return np.where(r < R, res, 0.)\n",
        "\n",
        "\n",
        "  def sph_harm(m, l, phi, theta):\n",
        "    am = np.abs(m)\n",
        "    t = np.cos(theta)\n",
        "    p_lm = np.polyval(legendre_coefs[l, am, :], t)*(1 - t**2)**(am/2.)\n",
        "    trig = jax.lax.cond(m >= 0, np.cos, np.sin, am*phi)\n",
        "    return p_lm*normalization_coefs[l, am]*trig\n",
        "\n",
        "  sph_harm = np.vectorize(sph_harm)\n",
        "\n",
        "\n",
        "  evaluate_radial_comp = radial_comp_fourier # TODO (?) implement different types\n",
        "\n",
        "  # we evaluate all the coefs that will be used in computations on the CPU\n",
        "  # then load them to GPU\n",
        "  legendre_coefs = np.array(get_assoc_legendre_coefs(l_max))\n",
        "  normalization_coefs = np.array(get_normalization_coefs(l_max))\n",
        "  @jax.jit\n",
        "  def evaluate_decomposition_coefs(x):\n",
        "    r, theta, phi = cartesian_to_spheric(x)\n",
        "\n",
        "    rr, kk = np.meshgrid(r, ks, indexing='ij')\n",
        "    rad_comp = evaluate_radial_comp(kk, rr)\n",
        "\n",
        "    pphi, ll, mm = np.meshgrid(phi, ls, ms, indexing='ij')\n",
        "    ttheta = np.broadcast_to(theta, pphi.T.shape).T\n",
        "\n",
        "    ang_comp = sph_harm(mm, ll, pphi, ttheta)\n",
        "    \n",
        "    return np.tensordot(rad_comp, ang_comp, axes=([0], [0]))\n",
        "\n",
        "  @jax.jit\n",
        "  def evaluate_ri_descriptors(x):\n",
        "    C = evaluate_decomposition_coefs(x)\n",
        "    return np.linalg.norm(C, axis=2, ord=2)\n",
        "\n",
        "  return evaluate_ri_descriptors, (2*k_max + 1, l_max + 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtkK9rVJuvwV"
      },
      "source": [
        "from jax_md import partition\n",
        "\n",
        "# R is a hyperparameter defining the radius of interaction\n",
        "# is taken similar to baseline JAX-MD notebook\n",
        "\n",
        "R = 3.0\n",
        "box_size = 10.862  # The size of the simulation region (as in JAX-MD notebook)\n",
        "displacement, shift = space.periodic(box_size)\n",
        "\n",
        "displacement_from_particle = jax.jit(jax.vmap(displacement, in_axes=(0, None)))\n",
        "\n",
        "neighbor_list_fn = partition.neighbor_list(displacement, box_size=box_size, r_cutoff=R, dr_threshold=0.0)\n",
        "_neighbor_lists = neighbor_list_fn(train_positions[0, :, :])\n",
        "\n",
        "evaluate_features, features_shape = get_feature_evaluation_function(k_max=10, l_max=10, R=R)\n",
        "\n",
        "evaluate_features = jax.jit(evaluate_features)\n",
        "\n",
        "N_ri_features = features_shape[0]*features_shape[1]\n",
        "\n",
        "\n",
        "no_hidden_units = 30\n",
        "init_fun, _E = stax.serial(\n",
        "    stax.Dense(no_hidden_units), stax.Relu, # hidden layer 1\n",
        "    stax.Dense(no_hidden_units), stax.Relu, # hidden layer 2\n",
        "    stax.Dense(no_hidden_units), stax.Relu, # hidden layer 3\n",
        "    stax.Dense(1))  # readout  \n",
        "E_p = lambda params, features: _E(params, features)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def evaluate_config_energy(params, conf_positions: np.array):  \n",
        "  N_particles, dim = conf_positions.shape\n",
        "  neighbor_lists = neighbor_list_fn(conf_positions, _neighbor_lists)\n",
        "  # TODO eradicate python cycle somehow\n",
        "\n",
        "  E_config = 0.\n",
        "  \n",
        "  for p in range(N_particles):\n",
        "    neighbor_idx = neighbor_lists.idx[p, :]\n",
        "    x = displacement_from_particle(conf_positions[neighbor_idx, :], conf_positions[p, :])\n",
        "\n",
        "    neighbor_idx = np.broadcast_to(neighbor_idx, (3, neighbor_idx.shape[0])).T\n",
        "    x = np.where(neighbor_idx == N_particles, R, x)\n",
        "\n",
        "    f = evaluate_features(x, ).ravel()\n",
        "\n",
        "    E_config += E_p(params, f.ravel())[0]\n",
        "\n",
        "  return E_config\n",
        "\n",
        "energy_grad = jax.grad(evaluate_config_energy, argnums=1)\n",
        "force_fn =  lambda params, conf_pos, **kwargs: -energy_grad(params, conf_pos)\n",
        "\n",
        "vectorized_energy = jax.jit(jax.vmap(evaluate_config_energy, in_axes=(None, 0)))\n",
        "vectorized_force = jax.jit(jax.vmap(force_fn, in_axes=(None, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oET76dlb8up"
      },
      "source": [
        "### Defining the NN architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLynd_Hh_Bla"
      },
      "source": [
        "key = jax.random.PRNGKey(42)\n",
        "key, net_key = random.split(key)\n",
        "_, params = init_fun(net_key, (-1,  -1, N_ri_features))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpIxcAu0rbdy"
      },
      "source": [
        "@jax.jit\n",
        "def loss(params, positions, E_ref, Fs_ref):\n",
        "  E_pred = vectorized_energy(params, positions)\n",
        "  E_rmse = np.mean((E_pred - E_ref)**2)\n",
        "\n",
        "  \n",
        "  Fs_pred = vectorized_force(params, positions)\n",
        "  Fs_rmse = np.mean(((Fs_pred - Fs_ref)**2).sum(axis=(1,2)))\n",
        "\n",
        "  regularizer = 0 # TODO invent a regularizer\n",
        "  return E_rmse + Fs_rmse + regularizer\n",
        "grad_loss = jax.jit(grad(loss, argnums=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enhf8bM9yeoZ"
      },
      "source": [
        "To train our neural network, we will use JAX's optimizers. As with our simulation functions, optimizers return a triple e.g. `(opt_init, opt_update, get_params) = optimizers.adam(step_size)`. Here `state = opt_init(params)` initializes the optimizers state, `state = opt_update(step, dparams, state)` updates the state of the optimizer using gradients, and `params = opt_params(state)` gets parameters from an optimizer state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia8JNbFPcCwg"
      },
      "source": [
        "### Defining the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tON2dbkU01p8",
        "outputId": "e35a5db0-2284-40ff-8ede-f0342898572d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF0m-DLe1FCo"
      },
      "source": [
        "basedir = '/content/drive/MyDrive/Colab Notebooks/ml_md_output'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O8IpMeKwQea"
      },
      "source": [
        "train_steps = 1001\n",
        "print_every = 200\n",
        "batch_size = 50\n",
        "\n",
        "no_training_samples = train_positions.shape[0]\n",
        "\n",
        "training_samples = np.arange(no_training_samples)\n",
        "\n",
        "\n",
        "# Initialize the network.\n",
        "key = jax.random.PRNGKey(42)\n",
        "key, net_key = random.split(key)\n",
        "_, params = init_fun(net_key, (-1,  -1, N_ri_features))\n",
        "\n",
        "# Create the optimizer.\n",
        "# 30k steps, 28 mev/atom\n",
        "#opt_init, opt_update, get_params = optimizers.adam(1e-3)\n",
        "\n",
        "lr_schedule = optimizers.make_schedule(lambda k: 1e-4/np.sqrt(k + 1000))\n",
        "#lr_schedule = optimizers.make_schedule(5e-6)\n",
        "opt_init, opt_update, get_params = optimizers.nesterov(lr_schedule, .1)\n",
        "state = opt_init(params)\n",
        "\n",
        "# Define and jit a single update step.\n",
        "@jit\n",
        "def update_step(state, batch, i):\n",
        "  positions, E_ref, Fs_ref = batch\n",
        "  params = get_params(state)\n",
        "  d_params = grad_loss(params, positions, E_ref, Fs_ref)\n",
        "  return opt_update(i, d_params, state)\n",
        "\n",
        "\n",
        "def batch(key):\n",
        "  steps_per_epoch = no_training_samples // batch_size \n",
        "  train_epochs = train_steps // steps_per_epoch\n",
        "  print(f'# of epochs: {train_epochs}')\n",
        "  for s in range(train_epochs):\n",
        "    key, split = random.split(key)\n",
        "    permutation = random.shuffle(split, training_samples)\n",
        "    for i in range(0, no_training_samples, batch_size):\n",
        "      batch_data = (train_positions[permutation[i:i + batch_size], :, :],\n",
        "                    train_energies[permutation[i:i + batch_size]],\n",
        "                    train_forces[permutation[i:i + batch_size], :, :]\n",
        "                    )\n",
        "      yield batch_data\n",
        "  \n",
        "\n",
        "best_params = get_params(state)\n",
        "min_loss = loss(best_params, train_positions, train_energies, train_forces)\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "opt_init, opt_update, get_params = optimizers.adam(1e-3)\n",
        "state = opt_init(params)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GUX0YP2cLWOR",
        "outputId": "fcd78ba5-86d2-4216-a4ef-ba01f1d5aecf"
      },
      "source": [
        "train_steps = 600001\n",
        "\n",
        "\n",
        "# Do the training.\n",
        "t = time.time()\n",
        "\n",
        "for i, b in ProgressIter(enumerate(batch(key)), train_steps):\n",
        "  state = update_step(state, b, i)\n",
        "  \n",
        "  # Print some diagnostics.\n",
        "  if i and i % print_every == 0:\n",
        "    dt = time.time() - t\n",
        "\n",
        "    cur_params = get_params(state)\n",
        "\n",
        "    train_loss = loss(cur_params, train_positions, train_energies, train_forces)\n",
        "    train_losses += [train_loss]\n",
        "    \n",
        "    test_loss = loss(cur_params, test_positions, test_energies, test_forces)\n",
        "    test_losses += [test_loss]\n",
        "\n",
        "    if train_loss < min_loss:  \n",
        "      min_loss = train_loss\n",
        "      best_params = cur_params\n",
        "\n",
        "    print(('Time: {:5.2f}\\tStep: {:4d}\\t'\n",
        "           'Training-loss: {:5.4f}\\tTest-loss: {:5.4f}').format(\n",
        "         dt, i, train_loss, test_loss))\n",
        "    t = time.time()\n",
        "    with open('losses.pkl', 'wb') as ofile:\n",
        "      pickle.dump({'train': train_losses, 'test': test_losses}, ofile)\n",
        "\n",
        "    try:\n",
        "      os.remove(os.path.join(basedir, 'weights.npz'), )\n",
        "    except FileNotFoundError:\n",
        "      pass\n",
        "    np.save(os.path.join(basedir, 'weights.npz'), best_params, )\n",
        "    with open(os.path.join(basedir, 'losses.pkl'), 'wb') as ofile:\n",
        "      pickle.dump({'train': train_losses, 'test': test_losses}, ofile)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='209725'\n",
              "            max='600001',\n",
              "            style='width: 45%'\n",
              "        >\n",
              "            209725\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "# of epochs: 12500\n",
            "Time: 25.70\tStep:  200\tTraining-loss: 358.0490\tTest-loss: 356.7678\n",
            "Time: 25.59\tStep:  400\tTraining-loss: 234.2233\tTest-loss: 233.4861\n",
            "Time: 25.57\tStep:  600\tTraining-loss: 166.0791\tTest-loss: 165.8109\n",
            "Time: 25.56\tStep:  800\tTraining-loss: 130.6592\tTest-loss: 130.6222\n",
            "Time: 25.56\tStep: 1000\tTraining-loss: 108.0339\tTest-loss: 108.2891\n",
            "Time: 25.54\tStep: 1200\tTraining-loss: 93.6906\tTest-loss: 94.7480\n",
            "Time: 25.55\tStep: 1400\tTraining-loss: 83.4794\tTest-loss: 84.4741\n",
            "Time: 25.54\tStep: 1600\tTraining-loss: 76.6676\tTest-loss: 77.3729\n",
            "Time: 25.54\tStep: 1800\tTraining-loss: 71.5121\tTest-loss: 71.7311\n",
            "Time: 25.53\tStep: 2000\tTraining-loss: 64.8970\tTest-loss: 65.6805\n",
            "Time: 25.54\tStep: 2200\tTraining-loss: 60.6273\tTest-loss: 60.7539\n",
            "Time: 25.49\tStep: 2400\tTraining-loss: 57.4105\tTest-loss: 57.7579\n",
            "Time: 25.54\tStep: 2600\tTraining-loss: 56.0557\tTest-loss: 55.8751\n",
            "Time: 25.53\tStep: 2800\tTraining-loss: 48.3600\tTest-loss: 48.7014\n",
            "Time: 25.53\tStep: 3000\tTraining-loss: 44.0282\tTest-loss: 44.1468\n",
            "Time: 25.53\tStep: 3200\tTraining-loss: 42.8835\tTest-loss: 43.1666\n",
            "Time: 25.53\tStep: 3400\tTraining-loss: 38.2383\tTest-loss: 38.1393\n",
            "Time: 25.53\tStep: 3600\tTraining-loss: 46.0144\tTest-loss: 45.5373\n",
            "Time: 25.53\tStep: 3800\tTraining-loss: 32.5470\tTest-loss: 32.5687\n",
            "Time: 25.53\tStep: 4000\tTraining-loss: 31.1008\tTest-loss: 31.0608\n",
            "Time: 25.54\tStep: 4200\tTraining-loss: 28.3982\tTest-loss: 28.5663\n",
            "Time: 25.55\tStep: 4400\tTraining-loss: 29.3480\tTest-loss: 29.6756\n",
            "Time: 25.54\tStep: 4600\tTraining-loss: 24.2646\tTest-loss: 24.3648\n",
            "Time: 25.54\tStep: 4800\tTraining-loss: 24.3612\tTest-loss: 24.3737\n",
            "Time: 25.47\tStep: 5000\tTraining-loss: 20.7167\tTest-loss: 20.7921\n",
            "Time: 25.53\tStep: 5200\tTraining-loss: 19.6102\tTest-loss: 19.8628\n",
            "Time: 25.53\tStep: 5400\tTraining-loss: 17.9971\tTest-loss: 18.1412\n",
            "Time: 25.53\tStep: 5600\tTraining-loss: 17.5758\tTest-loss: 17.5239\n",
            "Time: 25.55\tStep: 5800\tTraining-loss: 18.1290\tTest-loss: 18.2375\n",
            "Time: 25.53\tStep: 6000\tTraining-loss: 15.7712\tTest-loss: 15.7415\n",
            "Time: 25.53\tStep: 6200\tTraining-loss: 14.5579\tTest-loss: 14.5988\n",
            "Time: 25.54\tStep: 6400\tTraining-loss: 17.2210\tTest-loss: 17.2059\n",
            "Time: 25.53\tStep: 6600\tTraining-loss: 14.1469\tTest-loss: 14.1907\n",
            "Time: 25.53\tStep: 6800\tTraining-loss: 13.0993\tTest-loss: 13.2495\n",
            "Time: 25.53\tStep: 7000\tTraining-loss: 22.6529\tTest-loss: 22.6593\n",
            "Time: 25.53\tStep: 7200\tTraining-loss: 12.1179\tTest-loss: 12.2272\n",
            "Time: 25.47\tStep: 7400\tTraining-loss: 11.5015\tTest-loss: 11.7487\n",
            "Time: 25.53\tStep: 7600\tTraining-loss: 13.3471\tTest-loss: 13.6621\n",
            "Time: 25.53\tStep: 7800\tTraining-loss: 13.1205\tTest-loss: 13.3497\n",
            "Time: 25.53\tStep: 8000\tTraining-loss: 10.7756\tTest-loss: 11.0344\n",
            "Time: 25.53\tStep: 8200\tTraining-loss: 11.3479\tTest-loss: 11.4422\n",
            "Time: 25.53\tStep: 8400\tTraining-loss: 10.2973\tTest-loss: 10.3871\n",
            "Time: 25.53\tStep: 8600\tTraining-loss: 13.3262\tTest-loss: 13.5070\n",
            "Time: 25.54\tStep: 8800\tTraining-loss: 10.0026\tTest-loss: 10.1373\n",
            "Time: 25.52\tStep: 9000\tTraining-loss: 9.7818\tTest-loss: 9.9055\n",
            "Time: 25.52\tStep: 9200\tTraining-loss: 10.4083\tTest-loss: 10.5251\n",
            "Time: 25.52\tStep: 9400\tTraining-loss: 11.1144\tTest-loss: 11.2385\n",
            "Time: 25.53\tStep: 9600\tTraining-loss: 9.4466\tTest-loss: 9.5164\n",
            "Time: 25.47\tStep: 9800\tTraining-loss: 10.4012\tTest-loss: 10.4778\n",
            "Time: 25.53\tStep: 10000\tTraining-loss: 9.5586\tTest-loss: 9.6198\n",
            "Time: 25.53\tStep: 10200\tTraining-loss: 10.6371\tTest-loss: 10.6941\n",
            "Time: 25.54\tStep: 10400\tTraining-loss: 13.8202\tTest-loss: 13.8975\n",
            "Time: 25.53\tStep: 10600\tTraining-loss: 9.3646\tTest-loss: 9.4448\n",
            "Time: 25.53\tStep: 10800\tTraining-loss: 11.0013\tTest-loss: 11.0685\n",
            "Time: 25.53\tStep: 11000\tTraining-loss: 8.7890\tTest-loss: 8.8551\n",
            "Time: 25.52\tStep: 11200\tTraining-loss: 8.7299\tTest-loss: 8.7972\n",
            "Time: 25.52\tStep: 11400\tTraining-loss: 8.7111\tTest-loss: 8.7732\n",
            "Time: 25.55\tStep: 11600\tTraining-loss: 8.9930\tTest-loss: 9.0358\n",
            "Time: 25.54\tStep: 11800\tTraining-loss: 8.5882\tTest-loss: 8.6228\n",
            "Time: 25.55\tStep: 12000\tTraining-loss: 12.2964\tTest-loss: 12.3344\n",
            "Time: 25.48\tStep: 12200\tTraining-loss: 10.1518\tTest-loss: 10.2093\n",
            "Time: 25.55\tStep: 12400\tTraining-loss: 8.8114\tTest-loss: 8.8923\n",
            "Time: 25.54\tStep: 12600\tTraining-loss: 11.8221\tTest-loss: 11.8737\n",
            "Time: 25.53\tStep: 12800\tTraining-loss: 8.7097\tTest-loss: 8.8136\n",
            "Time: 25.53\tStep: 13000\tTraining-loss: 8.2840\tTest-loss: 8.3804\n",
            "Time: 25.53\tStep: 13200\tTraining-loss: 8.3174\tTest-loss: 8.4037\n",
            "Time: 25.53\tStep: 13400\tTraining-loss: 10.2577\tTest-loss: 10.3252\n",
            "Time: 25.53\tStep: 13600\tTraining-loss: 9.3587\tTest-loss: 9.4666\n",
            "Time: 25.54\tStep: 13800\tTraining-loss: 11.6993\tTest-loss: 11.7302\n",
            "Time: 25.54\tStep: 14000\tTraining-loss: 8.8353\tTest-loss: 8.9637\n",
            "Time: 25.53\tStep: 14200\tTraining-loss: 8.0237\tTest-loss: 8.1372\n",
            "Time: 25.53\tStep: 14400\tTraining-loss: 11.7873\tTest-loss: 11.9659\n",
            "Time: 25.53\tStep: 14600\tTraining-loss: 8.0243\tTest-loss: 8.1403\n",
            "Time: 25.48\tStep: 14800\tTraining-loss: 8.3768\tTest-loss: 8.4765\n",
            "Time: 25.58\tStep: 15000\tTraining-loss: 8.0130\tTest-loss: 8.1039\n",
            "Time: 25.56\tStep: 15200\tTraining-loss: 8.6378\tTest-loss: 8.7759\n",
            "Time: 25.61\tStep: 15400\tTraining-loss: 8.1671\tTest-loss: 8.2820\n",
            "Time: 25.63\tStep: 15600\tTraining-loss: 8.6226\tTest-loss: 8.7464\n",
            "Time: 25.64\tStep: 15800\tTraining-loss: 13.7918\tTest-loss: 13.9656\n",
            "Time: 25.60\tStep: 16000\tTraining-loss: 9.3207\tTest-loss: 9.4335\n",
            "Time: 25.59\tStep: 16200\tTraining-loss: 7.7977\tTest-loss: 7.9459\n",
            "Time: 25.61\tStep: 16400\tTraining-loss: 10.7132\tTest-loss: 10.8176\n",
            "Time: 25.62\tStep: 16600\tTraining-loss: 8.5645\tTest-loss: 8.6868\n",
            "Time: 25.59\tStep: 16800\tTraining-loss: 11.1569\tTest-loss: 11.3156\n",
            "Time: 25.59\tStep: 17000\tTraining-loss: 7.7034\tTest-loss: 7.8512\n",
            "Time: 25.54\tStep: 17200\tTraining-loss: 8.0054\tTest-loss: 8.1134\n",
            "Time: 25.61\tStep: 17400\tTraining-loss: 10.2965\tTest-loss: 10.4223\n",
            "Time: 25.59\tStep: 17600\tTraining-loss: 9.6314\tTest-loss: 9.7714\n",
            "Time: 25.59\tStep: 17800\tTraining-loss: 7.7856\tTest-loss: 7.9179\n",
            "Time: 25.58\tStep: 18000\tTraining-loss: 7.6116\tTest-loss: 7.7577\n",
            "Time: 25.58\tStep: 18200\tTraining-loss: 7.8101\tTest-loss: 7.9530\n",
            "Time: 25.58\tStep: 18400\tTraining-loss: 8.2991\tTest-loss: 8.4256\n",
            "Time: 25.58\tStep: 18600\tTraining-loss: 8.0428\tTest-loss: 8.1923\n",
            "Time: 25.57\tStep: 18800\tTraining-loss: 7.7397\tTest-loss: 7.8990\n",
            "Time: 25.57\tStep: 19000\tTraining-loss: 7.6555\tTest-loss: 7.8238\n",
            "Time: 25.57\tStep: 19200\tTraining-loss: 7.4592\tTest-loss: 7.6154\n",
            "Time: 25.56\tStep: 19400\tTraining-loss: 8.1524\tTest-loss: 8.2805\n",
            "Time: 25.50\tStep: 19600\tTraining-loss: 9.7540\tTest-loss: 9.8516\n",
            "Time: 25.57\tStep: 19800\tTraining-loss: 7.6151\tTest-loss: 7.7719\n",
            "Time: 25.57\tStep: 20000\tTraining-loss: 12.6149\tTest-loss: 12.7042\n",
            "Time: 25.56\tStep: 20200\tTraining-loss: 8.1003\tTest-loss: 8.2384\n",
            "Time: 25.56\tStep: 20400\tTraining-loss: 8.2679\tTest-loss: 8.4578\n",
            "Time: 25.57\tStep: 20600\tTraining-loss: 7.5410\tTest-loss: 7.6592\n",
            "Time: 25.56\tStep: 20800\tTraining-loss: 7.6841\tTest-loss: 7.8145\n",
            "Time: 25.56\tStep: 21000\tTraining-loss: 7.7065\tTest-loss: 7.8524\n",
            "Time: 25.57\tStep: 21200\tTraining-loss: 7.4370\tTest-loss: 7.5868\n",
            "Time: 25.56\tStep: 21400\tTraining-loss: 7.6553\tTest-loss: 7.8196\n",
            "Time: 25.55\tStep: 21600\tTraining-loss: 7.4085\tTest-loss: 7.5742\n",
            "Time: 25.57\tStep: 21800\tTraining-loss: 12.5917\tTest-loss: 12.8510\n",
            "Time: 25.51\tStep: 22000\tTraining-loss: 7.3809\tTest-loss: 7.5454\n",
            "Time: 25.56\tStep: 22200\tTraining-loss: 7.4807\tTest-loss: 7.6351\n",
            "Time: 25.55\tStep: 22400\tTraining-loss: 8.8913\tTest-loss: 9.0496\n",
            "Time: 25.56\tStep: 22600\tTraining-loss: 7.3962\tTest-loss: 7.5541\n",
            "Time: 25.57\tStep: 22800\tTraining-loss: 7.6361\tTest-loss: 7.7856\n",
            "Time: 25.55\tStep: 23000\tTraining-loss: 7.3986\tTest-loss: 7.5881\n",
            "Time: 25.54\tStep: 23200\tTraining-loss: 11.4887\tTest-loss: 11.7211\n",
            "Time: 25.55\tStep: 23400\tTraining-loss: 7.3169\tTest-loss: 7.4846\n",
            "Time: 25.54\tStep: 23600\tTraining-loss: 7.3100\tTest-loss: 7.4711\n",
            "Time: 25.54\tStep: 23800\tTraining-loss: 7.2483\tTest-loss: 7.4056\n",
            "Time: 25.55\tStep: 24000\tTraining-loss: 7.3465\tTest-loss: 7.5135\n",
            "Time: 25.54\tStep: 24200\tTraining-loss: 7.8977\tTest-loss: 8.0882\n",
            "Time: 25.56\tStep: 24400\tTraining-loss: 8.3172\tTest-loss: 8.5090\n",
            "Time: 25.48\tStep: 24600\tTraining-loss: 8.2191\tTest-loss: 8.3465\n",
            "Time: 25.56\tStep: 24800\tTraining-loss: 7.7182\tTest-loss: 7.8537\n",
            "Time: 25.56\tStep: 25000\tTraining-loss: 7.7761\tTest-loss: 7.9815\n",
            "Time: 25.63\tStep: 25200\tTraining-loss: 8.1536\tTest-loss: 8.2975\n",
            "Time: 25.64\tStep: 25400\tTraining-loss: 7.5856\tTest-loss: 7.7807\n",
            "Time: 25.65\tStep: 25600\tTraining-loss: 11.1250\tTest-loss: 11.2139\n",
            "Time: 25.60\tStep: 25800\tTraining-loss: 7.1853\tTest-loss: 7.3398\n",
            "Time: 25.60\tStep: 26000\tTraining-loss: 10.3742\tTest-loss: 10.4231\n",
            "Time: 25.63\tStep: 26200\tTraining-loss: 7.2468\tTest-loss: 7.3988\n",
            "Time: 25.59\tStep: 26400\tTraining-loss: 10.6508\tTest-loss: 10.9195\n",
            "Time: 25.59\tStep: 26600\tTraining-loss: 7.2036\tTest-loss: 7.3673\n",
            "Time: 25.59\tStep: 26800\tTraining-loss: 8.4909\tTest-loss: 8.7092\n",
            "Time: 25.53\tStep: 27000\tTraining-loss: 8.2899\tTest-loss: 8.3905\n",
            "Time: 25.59\tStep: 27200\tTraining-loss: 7.5679\tTest-loss: 7.7753\n",
            "Time: 25.61\tStep: 27400\tTraining-loss: 8.4906\tTest-loss: 8.7057\n",
            "Time: 25.61\tStep: 27600\tTraining-loss: 7.7486\tTest-loss: 7.8923\n",
            "Time: 25.60\tStep: 27800\tTraining-loss: 7.0582\tTest-loss: 7.2360\n",
            "Time: 25.60\tStep: 28000\tTraining-loss: 7.3824\tTest-loss: 7.5285\n",
            "Time: 25.61\tStep: 28200\tTraining-loss: 7.2900\tTest-loss: 7.5021\n",
            "Time: 25.61\tStep: 28400\tTraining-loss: 7.1257\tTest-loss: 7.3079\n",
            "Time: 25.59\tStep: 28600\tTraining-loss: 7.8072\tTest-loss: 8.0429\n",
            "Time: 25.59\tStep: 28800\tTraining-loss: 7.6066\tTest-loss: 7.8041\n",
            "Time: 25.61\tStep: 29000\tTraining-loss: 7.5066\tTest-loss: 7.6781\n",
            "Time: 25.60\tStep: 29200\tTraining-loss: 7.0616\tTest-loss: 7.2332\n",
            "Time: 25.54\tStep: 29400\tTraining-loss: 10.7884\tTest-loss: 10.8744\n",
            "Time: 25.60\tStep: 29600\tTraining-loss: 7.6909\tTest-loss: 7.8424\n",
            "Time: 25.61\tStep: 29800\tTraining-loss: 7.4244\tTest-loss: 7.6122\n",
            "Time: 25.61\tStep: 30000\tTraining-loss: 8.3127\tTest-loss: 8.4564\n",
            "Time: 25.58\tStep: 30200\tTraining-loss: 7.6295\tTest-loss: 7.7610\n",
            "Time: 25.59\tStep: 30400\tTraining-loss: 8.3015\tTest-loss: 8.4961\n",
            "Time: 25.58\tStep: 30600\tTraining-loss: 7.1280\tTest-loss: 7.2956\n",
            "Time: 25.57\tStep: 30800\tTraining-loss: 7.1939\tTest-loss: 7.3450\n",
            "Time: 25.57\tStep: 31000\tTraining-loss: 7.1407\tTest-loss: 7.2966\n",
            "Time: 25.56\tStep: 31200\tTraining-loss: 7.1712\tTest-loss: 7.3952\n",
            "Time: 25.56\tStep: 31400\tTraining-loss: 7.7098\tTest-loss: 7.9451\n",
            "Time: 25.55\tStep: 31600\tTraining-loss: 7.0573\tTest-loss: 7.2440\n",
            "Time: 25.50\tStep: 31800\tTraining-loss: 7.2655\tTest-loss: 7.4493\n",
            "Time: 25.56\tStep: 32000\tTraining-loss: 8.0660\tTest-loss: 8.2657\n",
            "Time: 25.57\tStep: 32200\tTraining-loss: 7.7538\tTest-loss: 7.9902\n",
            "Time: 25.57\tStep: 32400\tTraining-loss: 7.4932\tTest-loss: 7.6810\n",
            "Time: 25.56\tStep: 32600\tTraining-loss: 7.4605\tTest-loss: 7.6963\n",
            "Time: 25.57\tStep: 32800\tTraining-loss: 7.8824\tTest-loss: 8.0990\n",
            "Time: 25.56\tStep: 33000\tTraining-loss: 7.0294\tTest-loss: 7.1683\n",
            "Time: 25.56\tStep: 33200\tTraining-loss: 7.5904\tTest-loss: 7.7103\n",
            "Time: 25.56\tStep: 33400\tTraining-loss: 7.1710\tTest-loss: 7.2503\n",
            "Time: 25.56\tStep: 33600\tTraining-loss: 11.8275\tTest-loss: 11.9980\n",
            "Time: 25.56\tStep: 33800\tTraining-loss: 7.0864\tTest-loss: 7.1986\n",
            "Time: 25.56\tStep: 34000\tTraining-loss: 7.4067\tTest-loss: 7.4727\n",
            "Time: 25.55\tStep: 34200\tTraining-loss: 7.5417\tTest-loss: 7.6508\n",
            "Time: 25.50\tStep: 34400\tTraining-loss: 13.2270\tTest-loss: 13.2975\n",
            "Time: 25.56\tStep: 34600\tTraining-loss: 7.2680\tTest-loss: 7.3989\n",
            "Time: 25.57\tStep: 34800\tTraining-loss: 7.6786\tTest-loss: 7.8014\n",
            "Time: 25.56\tStep: 35000\tTraining-loss: 7.1063\tTest-loss: 7.2677\n",
            "Time: 25.57\tStep: 35200\tTraining-loss: 7.2063\tTest-loss: 7.3381\n",
            "Time: 25.56\tStep: 35400\tTraining-loss: 7.0175\tTest-loss: 7.1746\n",
            "Time: 25.56\tStep: 35600\tTraining-loss: 7.9259\tTest-loss: 8.1270\n",
            "Time: 25.56\tStep: 35800\tTraining-loss: 7.3547\tTest-loss: 7.4767\n",
            "Time: 25.56\tStep: 36000\tTraining-loss: 8.2943\tTest-loss: 8.5294\n",
            "Time: 25.56\tStep: 36200\tTraining-loss: 7.0330\tTest-loss: 7.2075\n",
            "Time: 25.57\tStep: 36400\tTraining-loss: 7.7248\tTest-loss: 7.8347\n",
            "Time: 25.57\tStep: 36600\tTraining-loss: 7.8597\tTest-loss: 7.9694\n",
            "Time: 25.52\tStep: 36800\tTraining-loss: 7.0602\tTest-loss: 7.2251\n",
            "Time: 25.57\tStep: 37000\tTraining-loss: 6.9705\tTest-loss: 7.1306\n",
            "Time: 25.57\tStep: 37200\tTraining-loss: 7.2992\tTest-loss: 7.4295\n",
            "Time: 25.56\tStep: 37400\tTraining-loss: 7.0197\tTest-loss: 7.1430\n",
            "Time: 25.57\tStep: 37600\tTraining-loss: 8.1511\tTest-loss: 8.2807\n",
            "Time: 25.58\tStep: 37800\tTraining-loss: 7.1473\tTest-loss: 7.2335\n",
            "Time: 25.58\tStep: 38000\tTraining-loss: 7.1713\tTest-loss: 7.3038\n",
            "Time: 25.58\tStep: 38200\tTraining-loss: 7.6941\tTest-loss: 7.7677\n",
            "Time: 25.59\tStep: 38400\tTraining-loss: 7.1515\tTest-loss: 7.2829\n",
            "Time: 25.58\tStep: 38600\tTraining-loss: 9.3062\tTest-loss: 9.3812\n",
            "Time: 25.58\tStep: 38800\tTraining-loss: 7.8598\tTest-loss: 7.9093\n",
            "Time: 25.60\tStep: 39000\tTraining-loss: 9.1559\tTest-loss: 9.3561\n",
            "Time: 25.53\tStep: 39200\tTraining-loss: 7.1961\tTest-loss: 7.3634\n",
            "Time: 25.59\tStep: 39400\tTraining-loss: 7.3058\tTest-loss: 7.4584\n",
            "Time: 25.60\tStep: 39600\tTraining-loss: 7.1719\tTest-loss: 7.3375\n",
            "Time: 25.61\tStep: 39800\tTraining-loss: 7.6729\tTest-loss: 7.8371\n",
            "Time: 25.61\tStep: 40000\tTraining-loss: 6.9618\tTest-loss: 7.1474\n",
            "Time: 25.59\tStep: 40200\tTraining-loss: 10.5128\tTest-loss: 10.7837\n",
            "Time: 25.60\tStep: 40400\tTraining-loss: 8.0603\tTest-loss: 8.2006\n",
            "Time: 25.61\tStep: 40600\tTraining-loss: 9.5581\tTest-loss: 9.7548\n",
            "Time: 25.64\tStep: 40800\tTraining-loss: 6.9445\tTest-loss: 7.0828\n",
            "Time: 25.66\tStep: 41000\tTraining-loss: 7.0709\tTest-loss: 7.2507\n",
            "Time: 25.62\tStep: 41200\tTraining-loss: 8.9806\tTest-loss: 9.1699\n",
            "Time: 25.62\tStep: 41400\tTraining-loss: 7.0399\tTest-loss: 7.1990\n",
            "Time: 25.57\tStep: 41600\tTraining-loss: 7.0919\tTest-loss: 7.2643\n",
            "Time: 25.62\tStep: 41800\tTraining-loss: 6.9952\tTest-loss: 7.1439\n",
            "Time: 25.62\tStep: 42000\tTraining-loss: 7.3070\tTest-loss: 7.4285\n",
            "Time: 25.61\tStep: 42200\tTraining-loss: 7.2242\tTest-loss: 7.3542\n",
            "Time: 25.61\tStep: 42400\tTraining-loss: 11.8718\tTest-loss: 11.9129\n",
            "Time: 25.61\tStep: 42600\tTraining-loss: 7.1811\tTest-loss: 7.3267\n",
            "Time: 25.62\tStep: 42800\tTraining-loss: 7.0546\tTest-loss: 7.1684\n",
            "Time: 25.62\tStep: 43000\tTraining-loss: 7.4602\tTest-loss: 7.5679\n",
            "Time: 25.62\tStep: 43200\tTraining-loss: 7.0067\tTest-loss: 7.1408\n",
            "Time: 25.62\tStep: 43400\tTraining-loss: 7.4415\tTest-loss: 7.5957\n",
            "Time: 25.61\tStep: 43600\tTraining-loss: 7.1075\tTest-loss: 7.2571\n",
            "Time: 25.61\tStep: 43800\tTraining-loss: 7.7513\tTest-loss: 7.8280\n",
            "Time: 25.61\tStep: 44000\tTraining-loss: 8.7571\tTest-loss: 8.8238\n",
            "Time: 25.53\tStep: 44200\tTraining-loss: 7.1345\tTest-loss: 7.2239\n",
            "Time: 25.60\tStep: 44400\tTraining-loss: 6.9705\tTest-loss: 7.1008\n",
            "Time: 25.60\tStep: 44600\tTraining-loss: 8.6810\tTest-loss: 8.7290\n",
            "Time: 25.59\tStep: 44800\tTraining-loss: 8.8587\tTest-loss: 8.9120\n",
            "Time: 25.60\tStep: 45000\tTraining-loss: 7.0965\tTest-loss: 7.2325\n",
            "Time: 25.58\tStep: 45200\tTraining-loss: 7.3156\tTest-loss: 7.7746\n",
            "Time: 25.58\tStep: 45400\tTraining-loss: 6.9761\tTest-loss: 7.4457\n",
            "Time: 25.58\tStep: 45600\tTraining-loss: 6.9626\tTest-loss: 7.4412\n",
            "Time: 25.59\tStep: 45800\tTraining-loss: 10.1022\tTest-loss: 10.4890\n",
            "Time: 25.58\tStep: 46000\tTraining-loss: 6.8844\tTest-loss: 7.4149\n",
            "Time: 25.59\tStep: 46200\tTraining-loss: 7.0681\tTest-loss: 7.5517\n",
            "Time: 25.58\tStep: 46400\tTraining-loss: 6.7367\tTest-loss: 7.2415\n",
            "Time: 25.53\tStep: 46600\tTraining-loss: 6.8138\tTest-loss: 7.3596\n",
            "Time: 25.57\tStep: 46800\tTraining-loss: 8.0032\tTest-loss: 8.4624\n",
            "Time: 25.58\tStep: 47000\tTraining-loss: 6.9369\tTest-loss: 7.2871\n",
            "Time: 25.58\tStep: 47200\tTraining-loss: 8.6918\tTest-loss: 9.0818\n",
            "Time: 25.57\tStep: 47400\tTraining-loss: 6.8548\tTest-loss: 7.1633\n",
            "Time: 25.57\tStep: 47600\tTraining-loss: 7.3503\tTest-loss: 7.7072\n",
            "Time: 25.60\tStep: 47800\tTraining-loss: 9.9459\tTest-loss: 10.2060\n",
            "Time: 25.57\tStep: 48000\tTraining-loss: 8.4250\tTest-loss: 8.6258\n",
            "Time: 25.57\tStep: 48200\tTraining-loss: 9.4978\tTest-loss: 9.8988\n",
            "Time: 25.57\tStep: 48400\tTraining-loss: 6.8588\tTest-loss: 7.1378\n",
            "Time: 25.56\tStep: 48600\tTraining-loss: 8.4131\tTest-loss: 8.7294\n",
            "Time: 25.56\tStep: 48800\tTraining-loss: 6.9296\tTest-loss: 7.1158\n",
            "Time: 25.51\tStep: 49000\tTraining-loss: 6.9832\tTest-loss: 7.1429\n",
            "Time: 25.58\tStep: 49200\tTraining-loss: 6.9698\tTest-loss: 7.1154\n",
            "Time: 25.61\tStep: 49400\tTraining-loss: 6.8282\tTest-loss: 7.0221\n",
            "Time: 25.59\tStep: 49600\tTraining-loss: 7.9708\tTest-loss: 8.0981\n",
            "Time: 25.58\tStep: 49800\tTraining-loss: 7.3870\tTest-loss: 7.5709\n",
            "Time: 25.59\tStep: 50000\tTraining-loss: 10.4156\tTest-loss: 10.6145\n",
            "Time: 25.59\tStep: 50200\tTraining-loss: 7.0951\tTest-loss: 7.2251\n",
            "Time: 25.59\tStep: 50400\tTraining-loss: 6.9786\tTest-loss: 7.1034\n",
            "Time: 25.59\tStep: 50600\tTraining-loss: 6.9771\tTest-loss: 7.1257\n",
            "Time: 25.60\tStep: 50800\tTraining-loss: 6.9544\tTest-loss: 7.0708\n",
            "Time: 25.62\tStep: 51000\tTraining-loss: 7.6405\tTest-loss: 7.7067\n",
            "Time: 25.61\tStep: 51200\tTraining-loss: 6.8256\tTest-loss: 6.9816\n",
            "Time: 25.53\tStep: 51400\tTraining-loss: 7.2841\tTest-loss: 7.4594\n",
            "Time: 25.59\tStep: 51600\tTraining-loss: 9.2101\tTest-loss: 9.3012\n",
            "Time: 25.59\tStep: 51800\tTraining-loss: 7.6485\tTest-loss: 7.8418\n",
            "Time: 25.60\tStep: 52000\tTraining-loss: 9.5586\tTest-loss: 9.6057\n",
            "Time: 25.59\tStep: 52200\tTraining-loss: 7.6323\tTest-loss: 7.8273\n",
            "Time: 25.59\tStep: 52400\tTraining-loss: 7.2101\tTest-loss: 7.3746\n",
            "Time: 25.60\tStep: 52600\tTraining-loss: 7.2938\tTest-loss: 7.4822\n",
            "Time: 25.60\tStep: 52800\tTraining-loss: 6.8783\tTest-loss: 6.9940\n",
            "Time: 25.59\tStep: 53000\tTraining-loss: 7.7145\tTest-loss: 7.7972\n",
            "Time: 25.61\tStep: 53200\tTraining-loss: 6.7679\tTest-loss: 6.8526\n",
            "Time: 25.59\tStep: 53400\tTraining-loss: 7.1133\tTest-loss: 7.1996\n",
            "Time: 25.58\tStep: 53600\tTraining-loss: 6.7375\tTest-loss: 6.8041\n",
            "Time: 25.57\tStep: 53800\tTraining-loss: 6.8282\tTest-loss: 6.9084\n",
            "Time: 25.52\tStep: 54000\tTraining-loss: 7.4232\tTest-loss: 7.4770\n",
            "Time: 25.57\tStep: 54200\tTraining-loss: 6.9588\tTest-loss: 7.0548\n",
            "Time: 25.57\tStep: 54400\tTraining-loss: 7.6062\tTest-loss: 7.6548\n",
            "Time: 25.57\tStep: 54600\tTraining-loss: 7.1300\tTest-loss: 7.2014\n",
            "Time: 25.57\tStep: 54800\tTraining-loss: 6.7998\tTest-loss: 6.9016\n",
            "Time: 25.57\tStep: 55000\tTraining-loss: 6.9208\tTest-loss: 7.0342\n",
            "Time: 25.58\tStep: 55200\tTraining-loss: 6.6745\tTest-loss: 6.7459\n",
            "Time: 25.57\tStep: 55400\tTraining-loss: 8.0823\tTest-loss: 8.2211\n",
            "Time: 25.58\tStep: 55600\tTraining-loss: 7.0955\tTest-loss: 7.1449\n",
            "Time: 25.57\tStep: 55800\tTraining-loss: 6.8806\tTest-loss: 6.9481\n",
            "Time: 25.57\tStep: 56000\tTraining-loss: 8.8322\tTest-loss: 8.9963\n",
            "Time: 25.57\tStep: 56200\tTraining-loss: 8.0164\tTest-loss: 8.1680\n",
            "Time: 25.51\tStep: 56400\tTraining-loss: 8.0099\tTest-loss: 8.0209\n",
            "Time: 25.57\tStep: 56600\tTraining-loss: 7.0913\tTest-loss: 7.1356\n",
            "Time: 25.58\tStep: 56800\tTraining-loss: 6.8718\tTest-loss: 6.9064\n",
            "Time: 25.56\tStep: 57000\tTraining-loss: 7.1269\tTest-loss: 7.1381\n",
            "Time: 25.58\tStep: 57200\tTraining-loss: 9.0443\tTest-loss: 8.9443\n",
            "Time: 25.56\tStep: 57400\tTraining-loss: 6.6078\tTest-loss: 6.6945\n",
            "Time: 25.57\tStep: 57600\tTraining-loss: 6.7344\tTest-loss: 6.8231\n",
            "Time: 25.56\tStep: 57800\tTraining-loss: 6.5587\tTest-loss: 6.6258\n",
            "Time: 25.57\tStep: 58000\tTraining-loss: 6.7256\tTest-loss: 6.7809\n",
            "Time: 25.57\tStep: 58200\tTraining-loss: 6.5994\tTest-loss: 6.7048\n",
            "Time: 25.57\tStep: 58400\tTraining-loss: 6.9515\tTest-loss: 6.9699\n",
            "Time: 25.56\tStep: 58600\tTraining-loss: 6.6685\tTest-loss: 6.7398\n",
            "Time: 25.52\tStep: 58800\tTraining-loss: 8.3309\tTest-loss: 8.4297\n",
            "Time: 25.57\tStep: 59000\tTraining-loss: 7.0227\tTest-loss: 7.0474\n",
            "Time: 25.57\tStep: 59200\tTraining-loss: 6.6163\tTest-loss: 6.6556\n",
            "Time: 25.57\tStep: 59400\tTraining-loss: 6.8975\tTest-loss: 7.0066\n",
            "Time: 25.57\tStep: 59600\tTraining-loss: 6.4134\tTest-loss: 6.4589\n",
            "Time: 25.56\tStep: 59800\tTraining-loss: 7.4565\tTest-loss: 7.5104\n",
            "Time: 25.56\tStep: 60000\tTraining-loss: 6.7703\tTest-loss: 6.8175\n",
            "Time: 25.56\tStep: 60200\tTraining-loss: 6.4695\tTest-loss: 6.5308\n",
            "Time: 25.57\tStep: 60400\tTraining-loss: 7.3363\tTest-loss: 7.4537\n",
            "Time: 25.57\tStep: 60600\tTraining-loss: 7.6125\tTest-loss: 8.7526\n",
            "Time: 25.56\tStep: 60800\tTraining-loss: 6.5468\tTest-loss: 6.6193\n",
            "Time: 25.56\tStep: 61000\tTraining-loss: 6.7287\tTest-loss: 6.8137\n",
            "Time: 25.50\tStep: 61200\tTraining-loss: 6.7538\tTest-loss: 6.7910\n",
            "Time: 25.55\tStep: 61400\tTraining-loss: 6.9403\tTest-loss: 6.9713\n",
            "Time: 25.55\tStep: 61600\tTraining-loss: 7.4982\tTest-loss: 7.6307\n",
            "Time: 25.55\tStep: 61800\tTraining-loss: 7.4221\tTest-loss: 7.5343\n",
            "Time: 25.56\tStep: 62000\tTraining-loss: 6.4681\tTest-loss: 6.5255\n",
            "Time: 25.55\tStep: 62200\tTraining-loss: 6.7749\tTest-loss: 6.8196\n",
            "Time: 25.55\tStep: 62400\tTraining-loss: 7.0189\tTest-loss: 7.0738\n",
            "Time: 25.55\tStep: 62600\tTraining-loss: 7.1257\tTest-loss: 7.1718\n",
            "Time: 25.55\tStep: 62800\tTraining-loss: 6.9524\tTest-loss: 7.0642\n",
            "Time: 25.54\tStep: 63000\tTraining-loss: 6.5542\tTest-loss: 6.6119\n",
            "Time: 25.55\tStep: 63200\tTraining-loss: 6.4119\tTest-loss: 6.4838\n",
            "Time: 25.54\tStep: 63400\tTraining-loss: 7.1406\tTest-loss: 7.2214\n",
            "Time: 25.55\tStep: 63600\tTraining-loss: 6.4558\tTest-loss: 6.5602\n",
            "Time: 25.49\tStep: 63800\tTraining-loss: 6.6431\tTest-loss: 6.7184\n",
            "Time: 25.54\tStep: 64000\tTraining-loss: 6.9392\tTest-loss: 7.0013\n",
            "Time: 25.62\tStep: 64200\tTraining-loss: 6.5396\tTest-loss: 6.6068\n",
            "Time: 25.60\tStep: 64400\tTraining-loss: 6.8794\tTest-loss: 6.9402\n",
            "Time: 25.57\tStep: 64600\tTraining-loss: 6.6033\tTest-loss: 6.6613\n",
            "Time: 25.56\tStep: 64800\tTraining-loss: 6.6742\tTest-loss: 6.7333\n",
            "Time: 25.57\tStep: 65000\tTraining-loss: 6.7599\tTest-loss: 6.8950\n",
            "Time: 25.56\tStep: 65200\tTraining-loss: 6.4008\tTest-loss: 6.5387\n",
            "Time: 25.57\tStep: 65400\tTraining-loss: 6.5655\tTest-loss: 6.6873\n",
            "Time: 25.55\tStep: 65600\tTraining-loss: 6.3936\tTest-loss: 6.4740\n",
            "Time: 25.56\tStep: 65800\tTraining-loss: 8.3309\tTest-loss: 8.5217\n",
            "Time: 25.55\tStep: 66000\tTraining-loss: 6.5510\tTest-loss: 6.6508\n",
            "Time: 25.49\tStep: 66200\tTraining-loss: 7.4635\tTest-loss: 7.5509\n",
            "Time: 25.56\tStep: 66400\tTraining-loss: 6.4902\tTest-loss: 6.5771\n",
            "Time: 25.56\tStep: 66600\tTraining-loss: 6.6095\tTest-loss: 6.7284\n",
            "Time: 25.56\tStep: 66800\tTraining-loss: 6.6937\tTest-loss: 6.8738\n",
            "Time: 25.56\tStep: 67000\tTraining-loss: 6.4479\tTest-loss: 6.5473\n",
            "Time: 25.54\tStep: 67200\tTraining-loss: 6.7010\tTest-loss: 6.7791\n",
            "Time: 25.57\tStep: 67400\tTraining-loss: 7.0165\tTest-loss: 7.1623\n",
            "Time: 25.56\tStep: 67600\tTraining-loss: 6.3684\tTest-loss: 6.4909\n",
            "Time: 25.55\tStep: 67800\tTraining-loss: 6.6474\tTest-loss: 6.6791\n",
            "Time: 25.55\tStep: 68000\tTraining-loss: 6.9575\tTest-loss: 7.0528\n",
            "Time: 25.56\tStep: 68200\tTraining-loss: 6.6507\tTest-loss: 6.7835\n",
            "Time: 25.55\tStep: 68400\tTraining-loss: 6.3569\tTest-loss: 6.4709\n",
            "Time: 25.49\tStep: 68600\tTraining-loss: 6.6473\tTest-loss: 6.7162\n",
            "Time: 25.54\tStep: 68800\tTraining-loss: 6.4979\tTest-loss: 6.5953\n",
            "Time: 25.55\tStep: 69000\tTraining-loss: 6.9012\tTest-loss: 6.9748\n",
            "Time: 25.55\tStep: 69200\tTraining-loss: 6.3813\tTest-loss: 6.4908\n",
            "Time: 25.56\tStep: 69400\tTraining-loss: 6.3872\tTest-loss: 6.4992\n",
            "Time: 25.55\tStep: 69600\tTraining-loss: 6.4022\tTest-loss: 6.4930\n",
            "Time: 25.55\tStep: 69800\tTraining-loss: 7.2706\tTest-loss: 7.3893\n",
            "Time: 25.54\tStep: 70000\tTraining-loss: 7.0856\tTest-loss: 7.1733\n",
            "Time: 25.56\tStep: 70200\tTraining-loss: 6.2902\tTest-loss: 6.3747\n",
            "Time: 25.55\tStep: 70400\tTraining-loss: 6.4003\tTest-loss: 6.5090\n",
            "Time: 25.56\tStep: 70600\tTraining-loss: 6.8360\tTest-loss: 6.9731\n",
            "Time: 25.55\tStep: 70800\tTraining-loss: 6.4747\tTest-loss: 6.5762\n",
            "Time: 25.51\tStep: 71000\tTraining-loss: 6.8842\tTest-loss: 7.0084\n",
            "Time: 25.59\tStep: 71200\tTraining-loss: 6.3999\tTest-loss: 6.4832\n",
            "Time: 25.57\tStep: 71400\tTraining-loss: 8.0362\tTest-loss: 8.1725\n",
            "Time: 25.58\tStep: 71600\tTraining-loss: 6.0625\tTest-loss: 6.1645\n",
            "Time: 25.57\tStep: 71800\tTraining-loss: 6.5778\tTest-loss: 6.6226\n",
            "Time: 25.57\tStep: 72000\tTraining-loss: 6.4718\tTest-loss: 6.5360\n",
            "Time: 25.57\tStep: 72200\tTraining-loss: 6.6417\tTest-loss: 6.7193\n",
            "Time: 25.56\tStep: 72400\tTraining-loss: 6.2589\tTest-loss: 6.3712\n",
            "Time: 25.56\tStep: 72600\tTraining-loss: 6.7088\tTest-loss: 6.7861\n",
            "Time: 25.57\tStep: 72800\tTraining-loss: 6.1335\tTest-loss: 6.2271\n",
            "Time: 25.57\tStep: 73000\tTraining-loss: 6.6314\tTest-loss: 6.7474\n",
            "Time: 25.58\tStep: 73200\tTraining-loss: 6.3115\tTest-loss: 6.4000\n",
            "Time: 25.58\tStep: 73400\tTraining-loss: 6.1998\tTest-loss: 6.3375\n",
            "Time: 25.50\tStep: 73600\tTraining-loss: 6.4447\tTest-loss: 6.4787\n",
            "Time: 25.56\tStep: 73800\tTraining-loss: 6.2717\tTest-loss: 6.4140\n",
            "Time: 25.56\tStep: 74000\tTraining-loss: 6.9456\tTest-loss: 7.0839\n",
            "Time: 25.56\tStep: 74200\tTraining-loss: 6.1366\tTest-loss: 6.2939\n",
            "Time: 25.56\tStep: 74400\tTraining-loss: 6.4572\tTest-loss: 6.5846\n",
            "Time: 25.56\tStep: 74600\tTraining-loss: 6.1998\tTest-loss: 6.3481\n",
            "Time: 25.56\tStep: 74800\tTraining-loss: 6.3153\tTest-loss: 6.4425\n",
            "Time: 25.56\tStep: 75000\tTraining-loss: 6.8593\tTest-loss: 7.0528\n",
            "Time: 25.56\tStep: 75200\tTraining-loss: 6.2211\tTest-loss: 6.2969\n",
            "Time: 25.56\tStep: 75400\tTraining-loss: 8.1285\tTest-loss: 8.3549\n",
            "Time: 25.56\tStep: 75600\tTraining-loss: 6.2016\tTest-loss: 6.3537\n",
            "Time: 25.56\tStep: 75800\tTraining-loss: 6.5393\tTest-loss: 6.5845\n",
            "Time: 25.51\tStep: 76000\tTraining-loss: 7.3289\tTest-loss: 7.5806\n",
            "Time: 25.57\tStep: 76200\tTraining-loss: 6.1982\tTest-loss: 6.3231\n",
            "Time: 25.56\tStep: 76400\tTraining-loss: 6.1927\tTest-loss: 6.3278\n",
            "Time: 25.56\tStep: 76600\tTraining-loss: 6.6836\tTest-loss: 6.9041\n",
            "Time: 25.56\tStep: 76800\tTraining-loss: 7.4792\tTest-loss: 7.5738\n",
            "Time: 25.56\tStep: 77000\tTraining-loss: 6.1276\tTest-loss: 6.3130\n",
            "Time: 25.56\tStep: 77200\tTraining-loss: 8.4986\tTest-loss: 8.7376\n",
            "Time: 25.56\tStep: 77400\tTraining-loss: 7.2554\tTest-loss: 7.2936\n",
            "Time: 25.58\tStep: 77600\tTraining-loss: 6.3590\tTest-loss: 6.4592\n",
            "Time: 25.55\tStep: 77800\tTraining-loss: 6.0784\tTest-loss: 6.1604\n",
            "Time: 25.56\tStep: 78000\tTraining-loss: 6.2032\tTest-loss: 6.2648\n",
            "Time: 25.56\tStep: 78200\tTraining-loss: 8.5080\tTest-loss: 8.5537\n",
            "Time: 25.50\tStep: 78400\tTraining-loss: 7.9328\tTest-loss: 7.9511\n",
            "Time: 25.56\tStep: 78600\tTraining-loss: 6.3850\tTest-loss: 6.4387\n",
            "Time: 25.56\tStep: 78800\tTraining-loss: 6.2379\tTest-loss: 6.3478\n",
            "Time: 25.56\tStep: 79000\tTraining-loss: 6.6395\tTest-loss: 6.8265\n",
            "Time: 25.57\tStep: 79200\tTraining-loss: 6.3962\tTest-loss: 6.5126\n",
            "Time: 25.56\tStep: 79400\tTraining-loss: 6.0180\tTest-loss: 6.0978\n",
            "Time: 25.56\tStep: 79600\tTraining-loss: 6.5245\tTest-loss: 6.6097\n",
            "Time: 25.56\tStep: 79800\tTraining-loss: 7.6543\tTest-loss: 7.8894\n",
            "Time: 25.56\tStep: 80000\tTraining-loss: 6.4332\tTest-loss: 6.5078\n",
            "Time: 25.56\tStep: 80200\tTraining-loss: 6.3360\tTest-loss: 6.4451\n",
            "Time: 25.56\tStep: 80400\tTraining-loss: 6.1580\tTest-loss: 6.3655\n",
            "Time: 25.56\tStep: 80600\tTraining-loss: 6.2322\tTest-loss: 6.3965\n",
            "Time: 25.50\tStep: 80800\tTraining-loss: 7.3584\tTest-loss: 7.4153\n",
            "Time: 25.56\tStep: 81000\tTraining-loss: 6.1846\tTest-loss: 6.2636\n",
            "Time: 25.55\tStep: 81200\tTraining-loss: 6.2721\tTest-loss: 6.3971\n",
            "Time: 25.55\tStep: 81400\tTraining-loss: 6.8239\tTest-loss: 6.9096\n",
            "Time: 25.57\tStep: 81600\tTraining-loss: 6.5795\tTest-loss: 6.8344\n",
            "Time: 25.55\tStep: 81800\tTraining-loss: 6.6983\tTest-loss: 6.7761\n",
            "Time: 25.56\tStep: 82000\tTraining-loss: 6.2986\tTest-loss: 6.5033\n",
            "Time: 25.57\tStep: 82200\tTraining-loss: 6.2565\tTest-loss: 6.3889\n",
            "Time: 25.55\tStep: 82400\tTraining-loss: 6.0378\tTest-loss: 6.2033\n",
            "Time: 25.55\tStep: 82600\tTraining-loss: 6.0175\tTest-loss: 6.1128\n",
            "Time: 25.55\tStep: 82800\tTraining-loss: 6.6645\tTest-loss: 6.8455\n",
            "Time: 25.55\tStep: 83000\tTraining-loss: 6.2339\tTest-loss: 6.4012\n",
            "Time: 25.56\tStep: 83200\tTraining-loss: 7.5711\tTest-loss: 7.7171\n",
            "Time: 25.49\tStep: 83400\tTraining-loss: 5.8963\tTest-loss: 5.9995\n",
            "Time: 25.56\tStep: 83600\tTraining-loss: 5.9760\tTest-loss: 6.1058\n",
            "Time: 25.55\tStep: 83800\tTraining-loss: 5.8283\tTest-loss: 5.9644\n",
            "Time: 25.55\tStep: 84000\tTraining-loss: 6.8194\tTest-loss: 6.7791\n",
            "Time: 25.56\tStep: 84200\tTraining-loss: 6.2444\tTest-loss: 6.3390\n",
            "Time: 25.55\tStep: 84400\tTraining-loss: 6.3303\tTest-loss: 6.3787\n",
            "Time: 25.56\tStep: 84600\tTraining-loss: 6.0810\tTest-loss: 6.1855\n",
            "Time: 25.56\tStep: 84800\tTraining-loss: 6.6820\tTest-loss: 6.7579\n",
            "Time: 25.55\tStep: 85000\tTraining-loss: 6.0466\tTest-loss: 6.1382\n",
            "Time: 25.55\tStep: 85200\tTraining-loss: 6.0045\tTest-loss: 6.1215\n",
            "Time: 25.56\tStep: 85400\tTraining-loss: 6.0979\tTest-loss: 6.1913\n",
            "Time: 25.56\tStep: 85600\tTraining-loss: 6.0631\tTest-loss: 6.1590\n",
            "Time: 25.49\tStep: 85800\tTraining-loss: 5.9845\tTest-loss: 6.1399\n",
            "Time: 25.55\tStep: 86000\tTraining-loss: 6.1934\tTest-loss: 6.3338\n",
            "Time: 25.56\tStep: 86200\tTraining-loss: 6.3093\tTest-loss: 6.4173\n",
            "Time: 25.55\tStep: 86400\tTraining-loss: 6.5409\tTest-loss: 6.6104\n",
            "Time: 25.55\tStep: 86600\tTraining-loss: 7.5236\tTest-loss: 7.6501\n",
            "Time: 25.56\tStep: 86800\tTraining-loss: 6.0985\tTest-loss: 6.2022\n",
            "Time: 25.57\tStep: 87000\tTraining-loss: 6.0782\tTest-loss: 6.1339\n",
            "Time: 25.55\tStep: 87200\tTraining-loss: 6.0215\tTest-loss: 6.1076\n",
            "Time: 25.55\tStep: 87400\tTraining-loss: 6.1686\tTest-loss: 6.2082\n",
            "Time: 25.55\tStep: 87600\tTraining-loss: 6.0517\tTest-loss: 6.1176\n",
            "Time: 25.56\tStep: 87800\tTraining-loss: 7.0589\tTest-loss: 7.0879\n",
            "Time: 25.56\tStep: 88000\tTraining-loss: 6.4732\tTest-loss: 6.5870\n",
            "Time: 25.49\tStep: 88200\tTraining-loss: 6.3259\tTest-loss: 6.4224\n",
            "Time: 25.55\tStep: 88400\tTraining-loss: 6.0964\tTest-loss: 6.1659\n",
            "Time: 25.56\tStep: 88600\tTraining-loss: 6.0511\tTest-loss: 6.1188\n",
            "Time: 25.55\tStep: 88800\tTraining-loss: 6.0731\tTest-loss: 6.1494\n",
            "Time: 25.55\tStep: 89000\tTraining-loss: 6.2964\tTest-loss: 6.3534\n",
            "Time: 25.55\tStep: 89200\tTraining-loss: 6.0719\tTest-loss: 6.1433\n",
            "Time: 25.55\tStep: 89400\tTraining-loss: 7.1154\tTest-loss: 7.2501\n",
            "Time: 25.55\tStep: 89600\tTraining-loss: 6.0900\tTest-loss: 6.1969\n",
            "Time: 25.56\tStep: 89800\tTraining-loss: 6.1077\tTest-loss: 6.2092\n",
            "Time: 25.54\tStep: 90000\tTraining-loss: 6.1247\tTest-loss: 6.2174\n",
            "Time: 25.55\tStep: 90200\tTraining-loss: 9.1612\tTest-loss: 9.2827\n",
            "Time: 25.55\tStep: 90400\tTraining-loss: 6.2743\tTest-loss: 6.3504\n",
            "Time: 25.49\tStep: 90600\tTraining-loss: 7.1753\tTest-loss: 7.1394\n",
            "Time: 25.55\tStep: 90800\tTraining-loss: 6.4378\tTest-loss: 6.4512\n",
            "Time: 25.55\tStep: 91000\tTraining-loss: 6.0827\tTest-loss: 6.1428\n",
            "Time: 25.54\tStep: 91200\tTraining-loss: 7.2241\tTest-loss: 7.3500\n",
            "Time: 25.54\tStep: 91400\tTraining-loss: 7.1586\tTest-loss: 7.1341\n",
            "Time: 25.56\tStep: 91600\tTraining-loss: 6.5240\tTest-loss: 6.5450\n",
            "Time: 25.55\tStep: 91800\tTraining-loss: 7.2816\tTest-loss: 7.3883\n",
            "Time: 25.54\tStep: 92000\tTraining-loss: 6.5164\tTest-loss: 6.5328\n",
            "Time: 25.55\tStep: 92200\tTraining-loss: 7.3200\tTest-loss: 7.3215\n",
            "Time: 25.55\tStep: 92400\tTraining-loss: 7.1794\tTest-loss: 7.2947\n",
            "Time: 25.54\tStep: 92600\tTraining-loss: 6.5205\tTest-loss: 6.6114\n",
            "Time: 25.55\tStep: 92800\tTraining-loss: 6.6525\tTest-loss: 6.6703\n",
            "Time: 25.54\tStep: 93000\tTraining-loss: 6.1975\tTest-loss: 6.2392\n",
            "Time: 25.49\tStep: 93200\tTraining-loss: 6.1126\tTest-loss: 6.1679\n",
            "Time: 25.54\tStep: 93400\tTraining-loss: 6.7505\tTest-loss: 6.7468\n",
            "Time: 25.55\tStep: 93600\tTraining-loss: 8.9859\tTest-loss: 8.9641\n",
            "Time: 25.55\tStep: 93800\tTraining-loss: 6.0867\tTest-loss: 6.1311\n",
            "Time: 25.54\tStep: 94000\tTraining-loss: 6.4401\tTest-loss: 6.5255\n",
            "Time: 25.55\tStep: 94200\tTraining-loss: 7.0486\tTest-loss: 7.0330\n",
            "Time: 25.55\tStep: 94400\tTraining-loss: 6.1146\tTest-loss: 6.1389\n",
            "Time: 25.54\tStep: 94600\tTraining-loss: 6.0356\tTest-loss: 6.0621\n",
            "Time: 25.53\tStep: 94800\tTraining-loss: 5.9982\tTest-loss: 6.0335\n",
            "Time: 25.53\tStep: 95000\tTraining-loss: 6.0115\tTest-loss: 6.0578\n",
            "Time: 25.52\tStep: 95200\tTraining-loss: 7.5166\tTest-loss: 7.4945\n",
            "Time: 25.52\tStep: 95400\tTraining-loss: 6.5125\tTest-loss: 6.5928\n",
            "Time: 25.47\tStep: 95600\tTraining-loss: 6.0805\tTest-loss: 6.1104\n",
            "Time: 25.59\tStep: 95800\tTraining-loss: 6.0484\tTest-loss: 6.0962\n",
            "Time: 25.54\tStep: 96000\tTraining-loss: 6.1004\tTest-loss: 6.1463\n",
            "Time: 25.59\tStep: 96200\tTraining-loss: 5.9110\tTest-loss: 5.9642\n",
            "Time: 25.53\tStep: 96400\tTraining-loss: 6.4539\tTest-loss: 6.4631\n",
            "Time: 25.53\tStep: 96600\tTraining-loss: 6.9240\tTest-loss: 7.0237\n",
            "Time: 25.53\tStep: 96800\tTraining-loss: 5.9112\tTest-loss: 5.9524\n",
            "Time: 25.55\tStep: 97000\tTraining-loss: 6.3014\tTest-loss: 6.3874\n",
            "Time: 25.52\tStep: 97200\tTraining-loss: 6.1719\tTest-loss: 6.2388\n",
            "Time: 25.54\tStep: 97400\tTraining-loss: 6.1928\tTest-loss: 6.1993\n",
            "Time: 25.52\tStep: 97600\tTraining-loss: 6.4010\tTest-loss: 6.5064\n",
            "Time: 25.54\tStep: 97800\tTraining-loss: 5.9730\tTest-loss: 6.0223\n",
            "Time: 25.51\tStep: 98000\tTraining-loss: 6.5223\tTest-loss: 6.6193\n",
            "Time: 25.59\tStep: 98200\tTraining-loss: 8.6251\tTest-loss: 8.6229\n",
            "Time: 25.56\tStep: 98400\tTraining-loss: 6.6397\tTest-loss: 6.6332\n",
            "Time: 25.54\tStep: 98600\tTraining-loss: 6.0304\tTest-loss: 6.0459\n",
            "Time: 25.55\tStep: 98800\tTraining-loss: 6.1860\tTest-loss: 6.2539\n",
            "Time: 25.55\tStep: 99000\tTraining-loss: 5.8999\tTest-loss: 5.9373\n",
            "Time: 25.55\tStep: 99200\tTraining-loss: 5.9339\tTest-loss: 5.9907\n",
            "Time: 25.54\tStep: 99400\tTraining-loss: 6.7807\tTest-loss: 6.7651\n",
            "Time: 25.55\tStep: 99600\tTraining-loss: 5.7775\tTest-loss: 5.8225\n",
            "Time: 25.55\tStep: 99800\tTraining-loss: 6.0672\tTest-loss: 6.1222\n",
            "Time: 25.55\tStep: 100000\tTraining-loss: 7.3544\tTest-loss: 7.2992\n",
            "Time: 25.55\tStep: 100200\tTraining-loss: 6.1365\tTest-loss: 6.1425\n",
            "Time: 25.49\tStep: 100400\tTraining-loss: 6.1352\tTest-loss: 6.1239\n",
            "Time: 25.55\tStep: 100600\tTraining-loss: 6.3544\tTest-loss: 6.4344\n",
            "Time: 25.55\tStep: 100800\tTraining-loss: 6.0407\tTest-loss: 6.0594\n",
            "Time: 25.55\tStep: 101000\tTraining-loss: 6.0526\tTest-loss: 6.0735\n",
            "Time: 25.55\tStep: 101200\tTraining-loss: 6.3088\tTest-loss: 6.3196\n",
            "Time: 25.55\tStep: 101400\tTraining-loss: 6.6522\tTest-loss: 6.6294\n",
            "Time: 25.54\tStep: 101600\tTraining-loss: 6.1859\tTest-loss: 6.2581\n",
            "Time: 25.55\tStep: 101800\tTraining-loss: 6.2179\tTest-loss: 6.2255\n",
            "Time: 25.56\tStep: 102000\tTraining-loss: 6.0356\tTest-loss: 6.0474\n",
            "Time: 25.55\tStep: 102200\tTraining-loss: 6.1278\tTest-loss: 6.1263\n",
            "Time: 25.55\tStep: 102400\tTraining-loss: 6.2638\tTest-loss: 6.3427\n",
            "Time: 25.56\tStep: 102600\tTraining-loss: 5.8024\tTest-loss: 5.8412\n",
            "Time: 25.55\tStep: 102800\tTraining-loss: 5.9268\tTest-loss: 5.9326\n",
            "Time: 25.49\tStep: 103000\tTraining-loss: 5.9810\tTest-loss: 6.0339\n",
            "Time: 25.54\tStep: 103200\tTraining-loss: 6.1069\tTest-loss: 6.1740\n",
            "Time: 25.54\tStep: 103400\tTraining-loss: 6.3880\tTest-loss: 6.3590\n",
            "Time: 25.55\tStep: 103600\tTraining-loss: 6.5548\tTest-loss: 6.6527\n",
            "Time: 25.54\tStep: 103800\tTraining-loss: 6.8502\tTest-loss: 6.9346\n",
            "Time: 25.55\tStep: 104000\tTraining-loss: 6.5040\tTest-loss: 6.4936\n",
            "Time: 25.56\tStep: 104200\tTraining-loss: 6.9975\tTest-loss: 6.9719\n",
            "Time: 25.54\tStep: 104400\tTraining-loss: 5.9322\tTest-loss: 5.9473\n",
            "Time: 25.55\tStep: 104600\tTraining-loss: 5.8271\tTest-loss: 5.8525\n",
            "Time: 25.54\tStep: 104800\tTraining-loss: 5.9083\tTest-loss: 5.9636\n",
            "Time: 25.55\tStep: 105000\tTraining-loss: 5.7937\tTest-loss: 5.8086\n",
            "Time: 25.54\tStep: 105200\tTraining-loss: 7.3361\tTest-loss: 7.3354\n",
            "Time: 25.48\tStep: 105400\tTraining-loss: 6.2463\tTest-loss: 6.3346\n",
            "Time: 25.55\tStep: 105600\tTraining-loss: 5.8866\tTest-loss: 5.9134\n",
            "Time: 25.58\tStep: 105800\tTraining-loss: 5.8151\tTest-loss: 5.8554\n",
            "Time: 25.59\tStep: 106000\tTraining-loss: 6.2866\tTest-loss: 6.2595\n",
            "Time: 25.58\tStep: 106200\tTraining-loss: 5.8824\tTest-loss: 5.9292\n",
            "Time: 25.59\tStep: 106400\tTraining-loss: 5.9425\tTest-loss: 5.9805\n",
            "Time: 25.57\tStep: 106600\tTraining-loss: 5.8720\tTest-loss: 5.8717\n",
            "Time: 25.57\tStep: 106800\tTraining-loss: 7.0136\tTest-loss: 6.9698\n",
            "Time: 25.56\tStep: 107000\tTraining-loss: 5.8863\tTest-loss: 5.8881\n",
            "Time: 25.56\tStep: 107200\tTraining-loss: 6.1641\tTest-loss: 6.2550\n",
            "Time: 25.56\tStep: 107400\tTraining-loss: 5.8872\tTest-loss: 5.9412\n",
            "Time: 25.54\tStep: 107600\tTraining-loss: 6.2114\tTest-loss: 6.2676\n",
            "Time: 25.49\tStep: 107800\tTraining-loss: 5.8968\tTest-loss: 5.8933\n",
            "Time: 25.55\tStep: 108000\tTraining-loss: 6.0053\tTest-loss: 6.0187\n",
            "Time: 25.55\tStep: 108200\tTraining-loss: 5.7825\tTest-loss: 5.8247\n",
            "Time: 25.55\tStep: 108400\tTraining-loss: 9.4792\tTest-loss: 9.3998\n",
            "Time: 25.55\tStep: 108600\tTraining-loss: 6.8022\tTest-loss: 6.9108\n",
            "Time: 25.55\tStep: 108800\tTraining-loss: 10.4251\tTest-loss: 10.3300\n",
            "Time: 25.56\tStep: 109000\tTraining-loss: 6.3914\tTest-loss: 6.3573\n",
            "Time: 25.54\tStep: 109200\tTraining-loss: 5.7338\tTest-loss: 5.7302\n",
            "Time: 25.54\tStep: 109400\tTraining-loss: 6.2497\tTest-loss: 6.3428\n",
            "Time: 25.55\tStep: 109600\tTraining-loss: 6.0071\tTest-loss: 6.0912\n",
            "Time: 25.55\tStep: 109800\tTraining-loss: 6.0451\tTest-loss: 6.1228\n",
            "Time: 25.55\tStep: 110000\tTraining-loss: 6.3230\tTest-loss: 6.3015\n",
            "Time: 25.49\tStep: 110200\tTraining-loss: 5.8765\tTest-loss: 5.8986\n",
            "Time: 25.55\tStep: 110400\tTraining-loss: 5.6690\tTest-loss: 5.6972\n",
            "Time: 25.55\tStep: 110600\tTraining-loss: 5.8968\tTest-loss: 5.8942\n",
            "Time: 25.55\tStep: 110800\tTraining-loss: 6.7159\tTest-loss: 6.7202\n",
            "Time: 25.55\tStep: 111000\tTraining-loss: 5.8625\tTest-loss: 5.8602\n",
            "Time: 25.55\tStep: 111200\tTraining-loss: 6.5431\tTest-loss: 6.6567\n",
            "Time: 25.55\tStep: 111400\tTraining-loss: 5.7953\tTest-loss: 5.8201\n",
            "Time: 25.55\tStep: 111600\tTraining-loss: 6.7566\tTest-loss: 6.7361\n",
            "Time: 25.55\tStep: 111800\tTraining-loss: 5.9066\tTest-loss: 5.9268\n",
            "Time: 25.56\tStep: 112000\tTraining-loss: 5.8543\tTest-loss: 5.8623\n",
            "Time: 25.56\tStep: 112200\tTraining-loss: 6.9276\tTest-loss: 6.9371\n",
            "Time: 25.55\tStep: 112400\tTraining-loss: 6.3005\tTest-loss: 6.4135\n",
            "Time: 25.55\tStep: 112600\tTraining-loss: 5.9335\tTest-loss: 5.9416\n",
            "Time: 25.49\tStep: 112800\tTraining-loss: 5.7087\tTest-loss: 5.7494\n",
            "Time: 25.55\tStep: 113000\tTraining-loss: 5.8107\tTest-loss: 5.8669\n",
            "Time: 25.55\tStep: 113200\tTraining-loss: 7.9770\tTest-loss: 7.9133\n",
            "Time: 25.55\tStep: 113400\tTraining-loss: 5.6161\tTest-loss: 5.6547\n",
            "Time: 25.56\tStep: 113600\tTraining-loss: 5.8236\tTest-loss: 5.8596\n",
            "Time: 25.55\tStep: 113800\tTraining-loss: 6.3171\tTest-loss: 6.2777\n",
            "Time: 25.55\tStep: 114000\tTraining-loss: 5.9250\tTest-loss: 6.0169\n",
            "Time: 25.56\tStep: 114200\tTraining-loss: 5.6527\tTest-loss: 5.6504\n",
            "Time: 25.56\tStep: 114400\tTraining-loss: 5.8878\tTest-loss: 5.9319\n",
            "Time: 25.55\tStep: 114600\tTraining-loss: 5.6617\tTest-loss: 5.7340\n",
            "Time: 25.54\tStep: 114800\tTraining-loss: 6.5358\tTest-loss: 6.6689\n",
            "Time: 25.55\tStep: 115000\tTraining-loss: 5.4602\tTest-loss: 5.4971\n",
            "Time: 25.50\tStep: 115200\tTraining-loss: 6.4160\tTest-loss: 6.5253\n",
            "Time: 25.55\tStep: 115400\tTraining-loss: 5.8740\tTest-loss: 5.8665\n",
            "Time: 25.55\tStep: 115600\tTraining-loss: 5.9647\tTest-loss: 5.9853\n",
            "Time: 25.55\tStep: 115800\tTraining-loss: 6.1366\tTest-loss: 6.1419\n",
            "Time: 25.55\tStep: 116000\tTraining-loss: 6.3887\tTest-loss: 6.4623\n",
            "Time: 25.56\tStep: 116200\tTraining-loss: 5.4732\tTest-loss: 5.5113\n",
            "Time: 25.54\tStep: 116400\tTraining-loss: 5.5839\tTest-loss: 5.5726\n",
            "Time: 25.55\tStep: 116600\tTraining-loss: 5.9604\tTest-loss: 5.9660\n",
            "Time: 25.56\tStep: 116800\tTraining-loss: 5.9431\tTest-loss: 5.9188\n",
            "Time: 25.55\tStep: 117000\tTraining-loss: 5.5823\tTest-loss: 5.6153\n",
            "Time: 25.54\tStep: 117200\tTraining-loss: 6.1870\tTest-loss: 6.3069\n",
            "Time: 25.55\tStep: 117400\tTraining-loss: 5.7641\tTest-loss: 5.8404\n",
            "Time: 25.49\tStep: 117600\tTraining-loss: 5.7388\tTest-loss: 5.7654\n",
            "Time: 25.55\tStep: 117800\tTraining-loss: 5.4634\tTest-loss: 5.4871\n",
            "Time: 25.55\tStep: 118000\tTraining-loss: 5.9129\tTest-loss: 5.9040\n",
            "Time: 25.56\tStep: 118200\tTraining-loss: 5.7369\tTest-loss: 5.7285\n",
            "Time: 25.56\tStep: 118400\tTraining-loss: 5.7419\tTest-loss: 5.7598\n",
            "Time: 25.56\tStep: 118600\tTraining-loss: 5.9173\tTest-loss: 5.9219\n",
            "Time: 25.55\tStep: 118800\tTraining-loss: 5.7044\tTest-loss: 5.7522\n",
            "Time: 25.55\tStep: 119000\tTraining-loss: 5.5889\tTest-loss: 5.6381\n",
            "Time: 25.55\tStep: 119200\tTraining-loss: 5.5289\tTest-loss: 5.5678\n",
            "Time: 25.56\tStep: 119400\tTraining-loss: 6.9982\tTest-loss: 7.0239\n",
            "Time: 25.55\tStep: 119600\tTraining-loss: 5.5108\tTest-loss: 5.5763\n",
            "Time: 25.55\tStep: 119800\tTraining-loss: 5.7384\tTest-loss: 5.8221\n",
            "Time: 25.50\tStep: 120000\tTraining-loss: 5.9106\tTest-loss: 6.0017\n",
            "Time: 25.56\tStep: 120200\tTraining-loss: 5.7516\tTest-loss: 5.7838\n",
            "Time: 25.55\tStep: 120400\tTraining-loss: 5.5536\tTest-loss: 5.6301\n",
            "Time: 25.55\tStep: 120600\tTraining-loss: 5.7771\tTest-loss: 5.7791\n",
            "Time: 25.55\tStep: 120800\tTraining-loss: 5.4865\tTest-loss: 5.5120\n",
            "Time: 25.55\tStep: 121000\tTraining-loss: 6.3131\tTest-loss: 6.3118\n",
            "Time: 25.55\tStep: 121200\tTraining-loss: 5.7542\tTest-loss: 5.8532\n",
            "Time: 25.55\tStep: 121400\tTraining-loss: 5.6927\tTest-loss: 5.6954\n",
            "Time: 25.56\tStep: 121600\tTraining-loss: 5.4130\tTest-loss: 5.4394\n",
            "Time: 25.55\tStep: 121800\tTraining-loss: 5.6772\tTest-loss: 5.6745\n",
            "Time: 25.55\tStep: 122000\tTraining-loss: 5.5167\tTest-loss: 5.5565\n",
            "Time: 25.56\tStep: 122200\tTraining-loss: 6.3650\tTest-loss: 6.3966\n",
            "Time: 25.56\tStep: 122400\tTraining-loss: 5.4935\tTest-loss: 5.5539\n",
            "Time: 25.49\tStep: 122600\tTraining-loss: 5.4277\tTest-loss: 5.4551\n",
            "Time: 25.55\tStep: 122800\tTraining-loss: 5.5966\tTest-loss: 5.6631\n",
            "Time: 25.56\tStep: 123000\tTraining-loss: 5.5810\tTest-loss: 5.6455\n",
            "Time: 25.55\tStep: 123200\tTraining-loss: 6.4698\tTest-loss: 6.4565\n",
            "Time: 25.55\tStep: 123400\tTraining-loss: 5.9245\tTest-loss: 5.9677\n",
            "Time: 25.55\tStep: 123600\tTraining-loss: 5.4995\tTest-loss: 5.5225\n",
            "Time: 25.55\tStep: 123800\tTraining-loss: 5.3685\tTest-loss: 5.3896\n",
            "Time: 25.54\tStep: 124000\tTraining-loss: 5.5480\tTest-loss: 5.5607\n",
            "Time: 25.53\tStep: 124200\tTraining-loss: 5.6353\tTest-loss: 5.6682\n",
            "Time: 25.54\tStep: 124400\tTraining-loss: 5.7684\tTest-loss: 5.7786\n",
            "Time: 25.54\tStep: 124600\tTraining-loss: 5.7638\tTest-loss: 5.7703\n",
            "Time: 25.53\tStep: 124800\tTraining-loss: 5.5959\tTest-loss: 5.6792\n",
            "Time: 25.47\tStep: 125000\tTraining-loss: 5.9683\tTest-loss: 6.0801\n",
            "Time: 25.53\tStep: 125200\tTraining-loss: 5.4295\tTest-loss: 5.4465\n",
            "Time: 25.53\tStep: 125400\tTraining-loss: 5.6154\tTest-loss: 5.6762\n",
            "Time: 25.53\tStep: 125600\tTraining-loss: 5.4408\tTest-loss: 5.4876\n",
            "Time: 25.53\tStep: 125800\tTraining-loss: 5.8832\tTest-loss: 5.8958\n",
            "Time: 25.53\tStep: 126000\tTraining-loss: 5.4529\tTest-loss: 5.4726\n",
            "Time: 25.54\tStep: 126200\tTraining-loss: 6.2923\tTest-loss: 6.4263\n",
            "Time: 25.54\tStep: 126400\tTraining-loss: 5.3300\tTest-loss: 5.3944\n",
            "Time: 25.53\tStep: 126600\tTraining-loss: 5.4757\tTest-loss: 5.5407\n",
            "Time: 25.53\tStep: 126800\tTraining-loss: 5.6452\tTest-loss: 5.6723\n",
            "Time: 25.53\tStep: 127000\tTraining-loss: 5.7583\tTest-loss: 5.7639\n",
            "Time: 25.53\tStep: 127200\tTraining-loss: 6.4317\tTest-loss: 6.4538\n",
            "Time: 25.47\tStep: 127400\tTraining-loss: 5.5012\tTest-loss: 5.5674\n",
            "Time: 25.56\tStep: 127600\tTraining-loss: 5.9768\tTest-loss: 6.0847\n",
            "Time: 25.61\tStep: 127800\tTraining-loss: 5.7021\tTest-loss: 5.7178\n",
            "Time: 25.58\tStep: 128000\tTraining-loss: 7.5472\tTest-loss: 7.7682\n",
            "Time: 25.55\tStep: 128200\tTraining-loss: 6.1745\tTest-loss: 6.3082\n",
            "Time: 25.56\tStep: 128400\tTraining-loss: 5.6565\tTest-loss: 5.7095\n",
            "Time: 25.54\tStep: 128600\tTraining-loss: 5.4976\tTest-loss: 5.5828\n",
            "Time: 25.59\tStep: 128800\tTraining-loss: 5.3889\tTest-loss: 5.4554\n",
            "Time: 25.55\tStep: 129000\tTraining-loss: 5.6156\tTest-loss: 5.7113\n",
            "Time: 25.55\tStep: 129200\tTraining-loss: 5.4495\tTest-loss: 5.5144\n",
            "Time: 25.59\tStep: 129400\tTraining-loss: 5.4587\tTest-loss: 5.5311\n",
            "Time: 25.59\tStep: 129600\tTraining-loss: 5.5585\tTest-loss: 5.5836\n",
            "Time: 25.49\tStep: 129800\tTraining-loss: 6.0270\tTest-loss: 6.1443\n",
            "Time: 25.58\tStep: 130000\tTraining-loss: 5.4569\tTest-loss: 5.5130\n",
            "Time: 25.59\tStep: 130200\tTraining-loss: 5.4622\tTest-loss: 5.5557\n",
            "Time: 25.56\tStep: 130400\tTraining-loss: 5.4098\tTest-loss: 5.4387\n",
            "Time: 25.55\tStep: 130600\tTraining-loss: 6.2317\tTest-loss: 6.3125\n",
            "Time: 25.58\tStep: 130800\tTraining-loss: 5.4294\tTest-loss: 5.4679\n",
            "Time: 25.56\tStep: 131000\tTraining-loss: 5.5365\tTest-loss: 5.6013\n",
            "Time: 25.55\tStep: 131200\tTraining-loss: 5.6294\tTest-loss: 5.6614\n",
            "Time: 25.56\tStep: 131400\tTraining-loss: 5.5845\tTest-loss: 5.6085\n",
            "Time: 25.54\tStep: 131600\tTraining-loss: 5.3753\tTest-loss: 5.4284\n",
            "Time: 25.54\tStep: 131800\tTraining-loss: 6.1811\tTest-loss: 6.3243\n",
            "Time: 25.53\tStep: 132000\tTraining-loss: 6.5099\tTest-loss: 6.5441\n",
            "Time: 25.54\tStep: 132200\tTraining-loss: 5.4117\tTest-loss: 5.4806\n",
            "Time: 25.49\tStep: 132400\tTraining-loss: 5.4858\tTest-loss: 5.5636\n",
            "Time: 25.53\tStep: 132600\tTraining-loss: 5.6646\tTest-loss: 5.7617\n",
            "Time: 25.53\tStep: 132800\tTraining-loss: 6.6075\tTest-loss: 6.6308\n",
            "Time: 25.53\tStep: 133000\tTraining-loss: 5.5132\tTest-loss: 5.6087\n",
            "Time: 25.53\tStep: 133200\tTraining-loss: 5.5492\tTest-loss: 5.6450\n",
            "Time: 25.53\tStep: 133400\tTraining-loss: 5.8240\tTest-loss: 5.9365\n",
            "Time: 25.53\tStep: 133600\tTraining-loss: 7.2490\tTest-loss: 7.3227\n",
            "Time: 25.53\tStep: 133800\tTraining-loss: 6.2746\tTest-loss: 6.4180\n",
            "Time: 25.54\tStep: 134000\tTraining-loss: 5.4622\tTest-loss: 5.5506\n",
            "Time: 25.54\tStep: 134200\tTraining-loss: 5.3296\tTest-loss: 5.3886\n",
            "Time: 25.53\tStep: 134400\tTraining-loss: 5.8516\tTest-loss: 5.8938\n",
            "Time: 25.53\tStep: 134600\tTraining-loss: 6.2150\tTest-loss: 6.2187\n",
            "Time: 25.48\tStep: 134800\tTraining-loss: 6.3672\tTest-loss: 6.3644\n",
            "Time: 25.54\tStep: 135000\tTraining-loss: 5.5134\tTest-loss: 5.6126\n",
            "Time: 25.54\tStep: 135200\tTraining-loss: 6.0862\tTest-loss: 6.1060\n",
            "Time: 25.53\tStep: 135400\tTraining-loss: 5.5782\tTest-loss: 5.5859\n",
            "Time: 25.54\tStep: 135600\tTraining-loss: 5.3179\tTest-loss: 5.3880\n",
            "Time: 25.54\tStep: 135800\tTraining-loss: 5.2860\tTest-loss: 5.3419\n",
            "Time: 25.54\tStep: 136000\tTraining-loss: 6.6609\tTest-loss: 6.6862\n",
            "Time: 25.54\tStep: 136200\tTraining-loss: 5.5753\tTest-loss: 5.6183\n",
            "Time: 25.54\tStep: 136400\tTraining-loss: 5.3284\tTest-loss: 5.4057\n",
            "Time: 25.54\tStep: 136600\tTraining-loss: 5.4156\tTest-loss: 5.4669\n",
            "Time: 25.54\tStep: 136800\tTraining-loss: 5.4806\tTest-loss: 5.5687\n",
            "Time: 25.53\tStep: 137000\tTraining-loss: 5.8465\tTest-loss: 5.8841\n",
            "Time: 25.48\tStep: 137200\tTraining-loss: 5.7078\tTest-loss: 5.7311\n",
            "Time: 25.53\tStep: 137400\tTraining-loss: 5.8785\tTest-loss: 5.9956\n",
            "Time: 25.53\tStep: 137600\tTraining-loss: 5.5383\tTest-loss: 5.5883\n",
            "Time: 25.53\tStep: 137800\tTraining-loss: 5.4879\tTest-loss: 5.5632\n",
            "Time: 25.53\tStep: 138000\tTraining-loss: 5.4005\tTest-loss: 5.4778\n",
            "Time: 25.53\tStep: 138200\tTraining-loss: 5.2856\tTest-loss: 5.3522\n",
            "Time: 25.52\tStep: 138400\tTraining-loss: 5.4926\tTest-loss: 5.5424\n",
            "Time: 25.53\tStep: 138600\tTraining-loss: 5.5592\tTest-loss: 5.6203\n",
            "Time: 25.53\tStep: 138800\tTraining-loss: 5.7217\tTest-loss: 5.8233\n",
            "Time: 25.53\tStep: 139000\tTraining-loss: 5.5850\tTest-loss: 5.6218\n",
            "Time: 25.52\tStep: 139200\tTraining-loss: 5.5743\tTest-loss: 5.6276\n",
            "Time: 25.53\tStep: 139400\tTraining-loss: 5.4992\tTest-loss: 5.5962\n",
            "Time: 25.46\tStep: 139600\tTraining-loss: 5.6713\tTest-loss: 5.7088\n",
            "Time: 25.52\tStep: 139800\tTraining-loss: 5.2183\tTest-loss: 5.2967\n",
            "Time: 25.52\tStep: 140000\tTraining-loss: 5.2434\tTest-loss: 5.3269\n",
            "Time: 25.53\tStep: 140200\tTraining-loss: 6.2524\tTest-loss: 6.2712\n",
            "Time: 25.53\tStep: 140400\tTraining-loss: 5.5141\tTest-loss: 5.5369\n",
            "Time: 25.53\tStep: 140600\tTraining-loss: 5.3054\tTest-loss: 5.3862\n",
            "Time: 25.52\tStep: 140800\tTraining-loss: 5.4043\tTest-loss: 5.4483\n",
            "Time: 25.52\tStep: 141000\tTraining-loss: 5.3434\tTest-loss: 5.4041\n",
            "Time: 25.52\tStep: 141200\tTraining-loss: 6.9266\tTest-loss: 7.1365\n",
            "Time: 25.53\tStep: 141400\tTraining-loss: 5.3277\tTest-loss: 5.3806\n",
            "Time: 25.53\tStep: 141600\tTraining-loss: 5.3411\tTest-loss: 5.4057\n",
            "Time: 25.54\tStep: 141800\tTraining-loss: 5.4009\tTest-loss: 5.4564\n",
            "Time: 25.52\tStep: 142000\tTraining-loss: 5.4223\tTest-loss: 5.5114\n",
            "Time: 25.47\tStep: 142200\tTraining-loss: 5.2735\tTest-loss: 5.3481\n",
            "Time: 25.52\tStep: 142400\tTraining-loss: 5.2454\tTest-loss: 5.3059\n",
            "Time: 25.53\tStep: 142600\tTraining-loss: 7.5678\tTest-loss: 7.6104\n",
            "Time: 25.52\tStep: 142800\tTraining-loss: 5.4872\tTest-loss: 5.5834\n",
            "Time: 25.52\tStep: 143000\tTraining-loss: 6.4587\tTest-loss: 6.5195\n",
            "Time: 25.52\tStep: 143200\tTraining-loss: 5.4109\tTest-loss: 5.5095\n",
            "Time: 25.53\tStep: 143400\tTraining-loss: 5.4822\tTest-loss: 5.5902\n",
            "Time: 25.53\tStep: 143600\tTraining-loss: 5.2342\tTest-loss: 5.2918\n",
            "Time: 25.52\tStep: 143800\tTraining-loss: 5.2004\tTest-loss: 5.2613\n",
            "Time: 25.52\tStep: 144000\tTraining-loss: 6.0224\tTest-loss: 6.1261\n",
            "Time: 25.53\tStep: 144200\tTraining-loss: 5.8982\tTest-loss: 5.9208\n",
            "Time: 25.53\tStep: 144400\tTraining-loss: 5.3978\tTest-loss: 5.4364\n",
            "Time: 25.47\tStep: 144600\tTraining-loss: 5.8568\tTest-loss: 5.8780\n",
            "Time: 25.53\tStep: 144800\tTraining-loss: 5.3877\tTest-loss: 5.4790\n",
            "Time: 25.53\tStep: 145000\tTraining-loss: 5.3219\tTest-loss: 5.4029\n",
            "Time: 25.53\tStep: 145200\tTraining-loss: 5.2350\tTest-loss: 5.3218\n",
            "Time: 25.54\tStep: 145400\tTraining-loss: 6.3135\tTest-loss: 6.3273\n",
            "Time: 25.53\tStep: 145600\tTraining-loss: 5.9720\tTest-loss: 5.9891\n",
            "Time: 25.53\tStep: 145800\tTraining-loss: 5.3506\tTest-loss: 5.4284\n",
            "Time: 25.53\tStep: 146000\tTraining-loss: 5.4061\tTest-loss: 5.5058\n",
            "Time: 25.53\tStep: 146200\tTraining-loss: 5.4238\tTest-loss: 5.4545\n",
            "Time: 25.53\tStep: 146400\tTraining-loss: 5.5408\tTest-loss: 5.6534\n",
            "Time: 25.56\tStep: 146600\tTraining-loss: 5.2289\tTest-loss: 5.2737\n",
            "Time: 25.53\tStep: 146800\tTraining-loss: 5.3090\tTest-loss: 5.3738\n",
            "Time: 25.47\tStep: 147000\tTraining-loss: 5.2261\tTest-loss: 5.2803\n",
            "Time: 25.52\tStep: 147200\tTraining-loss: 5.3690\tTest-loss: 5.4739\n",
            "Time: 25.53\tStep: 147400\tTraining-loss: 5.2219\tTest-loss: 5.2837\n",
            "Time: 25.53\tStep: 147600\tTraining-loss: 6.5085\tTest-loss: 6.6772\n",
            "Time: 25.53\tStep: 147800\tTraining-loss: 7.0008\tTest-loss: 7.0135\n",
            "Time: 25.53\tStep: 148000\tTraining-loss: 5.1854\tTest-loss: 5.2569\n",
            "Time: 25.53\tStep: 148200\tTraining-loss: 5.3555\tTest-loss: 5.4303\n",
            "Time: 25.53\tStep: 148400\tTraining-loss: 6.6288\tTest-loss: 6.6499\n",
            "Time: 25.53\tStep: 148600\tTraining-loss: 5.2305\tTest-loss: 5.2806\n",
            "Time: 25.54\tStep: 148800\tTraining-loss: 5.5805\tTest-loss: 5.6620\n",
            "Time: 25.53\tStep: 149000\tTraining-loss: 5.2185\tTest-loss: 5.3011\n",
            "Time: 25.53\tStep: 149200\tTraining-loss: 5.4661\tTest-loss: 5.4816\n",
            "Time: 25.47\tStep: 149400\tTraining-loss: 5.5327\tTest-loss: 5.5788\n",
            "Time: 25.53\tStep: 149600\tTraining-loss: 5.3404\tTest-loss: 5.4218\n",
            "Time: 25.53\tStep: 149800\tTraining-loss: 5.9268\tTest-loss: 6.0815\n",
            "Time: 25.53\tStep: 150000\tTraining-loss: 5.7916\tTest-loss: 5.8268\n",
            "Time: 25.54\tStep: 150200\tTraining-loss: 5.5265\tTest-loss: 5.5878\n",
            "Time: 25.53\tStep: 150400\tTraining-loss: 5.2622\tTest-loss: 5.3545\n",
            "Time: 25.53\tStep: 150600\tTraining-loss: 5.4100\tTest-loss: 5.5053\n",
            "Time: 25.54\tStep: 150800\tTraining-loss: 6.2959\tTest-loss: 6.3339\n",
            "Time: 25.53\tStep: 151000\tTraining-loss: 5.2709\tTest-loss: 5.3166\n",
            "Time: 25.54\tStep: 151200\tTraining-loss: 5.6900\tTest-loss: 5.7309\n",
            "Time: 25.53\tStep: 151400\tTraining-loss: 6.0835\tTest-loss: 6.0989\n",
            "Time: 25.53\tStep: 151600\tTraining-loss: 5.4085\tTest-loss: 5.5011\n",
            "Time: 25.53\tStep: 151800\tTraining-loss: 5.5644\tTest-loss: 5.6155\n",
            "Time: 25.47\tStep: 152000\tTraining-loss: 5.4444\tTest-loss: 5.4990\n",
            "Time: 25.53\tStep: 152200\tTraining-loss: 6.2409\tTest-loss: 6.3980\n",
            "Time: 25.53\tStep: 152400\tTraining-loss: 5.4280\tTest-loss: 5.4561\n",
            "Time: 25.52\tStep: 152600\tTraining-loss: 5.8995\tTest-loss: 5.8994\n",
            "Time: 25.55\tStep: 152800\tTraining-loss: 5.2415\tTest-loss: 5.2919\n",
            "Time: 25.53\tStep: 153000\tTraining-loss: 6.9726\tTest-loss: 6.9732\n",
            "Time: 25.52\tStep: 153200\tTraining-loss: 5.3874\tTest-loss: 5.4089\n",
            "Time: 25.53\tStep: 153400\tTraining-loss: 5.3728\tTest-loss: 5.4620\n",
            "Time: 25.53\tStep: 153600\tTraining-loss: 5.3394\tTest-loss: 5.4530\n",
            "Time: 25.53\tStep: 153800\tTraining-loss: 5.3812\tTest-loss: 5.4246\n",
            "Time: 25.53\tStep: 154000\tTraining-loss: 5.4990\tTest-loss: 5.5993\n",
            "Time: 25.53\tStep: 154200\tTraining-loss: 6.6599\tTest-loss: 6.7198\n",
            "Time: 25.48\tStep: 154400\tTraining-loss: 5.4427\tTest-loss: 5.4737\n",
            "Time: 25.53\tStep: 154600\tTraining-loss: 5.4164\tTest-loss: 5.4597\n",
            "Time: 25.53\tStep: 154800\tTraining-loss: 5.2552\tTest-loss: 5.3109\n",
            "Time: 25.53\tStep: 155000\tTraining-loss: 5.5391\tTest-loss: 5.6396\n",
            "Time: 25.53\tStep: 155200\tTraining-loss: 5.3766\tTest-loss: 5.4186\n",
            "Time: 25.53\tStep: 155400\tTraining-loss: 5.2292\tTest-loss: 5.3203\n",
            "Time: 25.53\tStep: 155600\tTraining-loss: 5.9839\tTest-loss: 6.1079\n",
            "Time: 25.53\tStep: 155800\tTraining-loss: 5.3458\tTest-loss: 5.4035\n",
            "Time: 25.54\tStep: 156000\tTraining-loss: 5.2149\tTest-loss: 5.2748\n",
            "Time: 25.53\tStep: 156200\tTraining-loss: 5.8759\tTest-loss: 5.9668\n",
            "Time: 25.53\tStep: 156400\tTraining-loss: 5.1572\tTest-loss: 5.2008\n",
            "Time: 25.53\tStep: 156600\tTraining-loss: 5.1419\tTest-loss: 5.1894\n",
            "Time: 25.47\tStep: 156800\tTraining-loss: 6.0716\tTest-loss: 6.2185\n",
            "Time: 25.53\tStep: 157000\tTraining-loss: 5.2195\tTest-loss: 5.2769\n",
            "Time: 25.53\tStep: 157200\tTraining-loss: 5.5162\tTest-loss: 5.5595\n",
            "Time: 25.53\tStep: 157400\tTraining-loss: 6.0250\tTest-loss: 6.0554\n",
            "Time: 25.52\tStep: 157600\tTraining-loss: 5.1704\tTest-loss: 5.2355\n",
            "Time: 25.53\tStep: 157800\tTraining-loss: 6.2109\tTest-loss: 6.2122\n",
            "Time: 25.53\tStep: 158000\tTraining-loss: 5.1409\tTest-loss: 5.2093\n",
            "Time: 25.53\tStep: 158200\tTraining-loss: 8.0666\tTest-loss: 8.0523\n",
            "Time: 25.52\tStep: 158400\tTraining-loss: 5.6009\tTest-loss: 5.6413\n",
            "Time: 25.53\tStep: 158600\tTraining-loss: 5.2583\tTest-loss: 5.3312\n",
            "Time: 25.53\tStep: 158800\tTraining-loss: 6.2248\tTest-loss: 6.3720\n",
            "Time: 25.54\tStep: 159000\tTraining-loss: 5.2897\tTest-loss: 5.3796\n",
            "Time: 25.47\tStep: 159200\tTraining-loss: 5.6182\tTest-loss: 5.6627\n",
            "Time: 25.53\tStep: 159400\tTraining-loss: 5.8451\tTest-loss: 5.8625\n",
            "Time: 25.53\tStep: 159600\tTraining-loss: 5.2285\tTest-loss: 5.3076\n",
            "Time: 25.53\tStep: 159800\tTraining-loss: 5.9337\tTest-loss: 5.9539\n",
            "Time: 25.53\tStep: 160000\tTraining-loss: 5.3322\tTest-loss: 5.4206\n",
            "Time: 25.53\tStep: 160200\tTraining-loss: 5.8367\tTest-loss: 5.8593\n",
            "Time: 25.53\tStep: 160400\tTraining-loss: 5.3212\tTest-loss: 5.4258\n",
            "Time: 25.53\tStep: 160600\tTraining-loss: 5.4616\tTest-loss: 5.5517\n",
            "Time: 25.53\tStep: 160800\tTraining-loss: 5.7474\tTest-loss: 5.7653\n",
            "Time: 25.53\tStep: 161000\tTraining-loss: 5.4402\tTest-loss: 5.5485\n",
            "Time: 25.52\tStep: 161200\tTraining-loss: 6.0987\tTest-loss: 6.1057\n",
            "Time: 25.53\tStep: 161400\tTraining-loss: 5.1038\tTest-loss: 5.1754\n",
            "Time: 25.53\tStep: 161600\tTraining-loss: 5.5511\tTest-loss: 5.6145\n",
            "Time: 25.47\tStep: 161800\tTraining-loss: 5.5790\tTest-loss: 5.5983\n",
            "Time: 25.53\tStep: 162000\tTraining-loss: 5.0994\tTest-loss: 5.1479\n",
            "Time: 25.54\tStep: 162200\tTraining-loss: 5.1572\tTest-loss: 5.2289\n",
            "Time: 25.53\tStep: 162400\tTraining-loss: 5.3022\tTest-loss: 5.3951\n",
            "Time: 25.53\tStep: 162600\tTraining-loss: 5.2433\tTest-loss: 5.3075\n",
            "Time: 25.53\tStep: 162800\tTraining-loss: 5.5282\tTest-loss: 5.5939\n",
            "Time: 25.54\tStep: 163000\tTraining-loss: 5.1856\tTest-loss: 5.2431\n",
            "Time: 25.52\tStep: 163200\tTraining-loss: 5.1033\tTest-loss: 5.1322\n",
            "Time: 25.53\tStep: 163400\tTraining-loss: 5.2615\tTest-loss: 5.3067\n",
            "Time: 25.53\tStep: 163600\tTraining-loss: 5.1963\tTest-loss: 5.2512\n",
            "Time: 25.54\tStep: 163800\tTraining-loss: 5.1438\tTest-loss: 5.2122\n",
            "Time: 25.53\tStep: 164000\tTraining-loss: 5.2508\tTest-loss: 5.3528\n",
            "Time: 25.47\tStep: 164200\tTraining-loss: 5.2712\tTest-loss: 5.3560\n",
            "Time: 25.53\tStep: 164400\tTraining-loss: 7.9623\tTest-loss: 8.0138\n",
            "Time: 25.53\tStep: 164600\tTraining-loss: 5.2043\tTest-loss: 5.2942\n",
            "Time: 25.53\tStep: 164800\tTraining-loss: 5.2620\tTest-loss: 5.3692\n",
            "Time: 25.53\tStep: 165000\tTraining-loss: 5.1952\tTest-loss: 5.2594\n",
            "Time: 25.53\tStep: 165200\tTraining-loss: 5.3259\tTest-loss: 5.3806\n",
            "Time: 25.53\tStep: 165400\tTraining-loss: 5.8841\tTest-loss: 5.9931\n",
            "Time: 25.53\tStep: 165600\tTraining-loss: 5.3612\tTest-loss: 5.4942\n",
            "Time: 25.52\tStep: 165800\tTraining-loss: 5.8841\tTest-loss: 5.9087\n",
            "Time: 25.52\tStep: 166000\tTraining-loss: 5.1130\tTest-loss: 5.1904\n",
            "Time: 25.53\tStep: 166200\tTraining-loss: 5.4446\tTest-loss: 5.4668\n",
            "Time: 25.53\tStep: 166400\tTraining-loss: 5.7388\tTest-loss: 5.8049\n",
            "Time: 25.46\tStep: 166600\tTraining-loss: 5.7806\tTest-loss: 5.8314\n",
            "Time: 25.53\tStep: 166800\tTraining-loss: 5.1233\tTest-loss: 5.2042\n",
            "Time: 25.53\tStep: 167000\tTraining-loss: 5.9104\tTest-loss: 5.9632\n",
            "Time: 25.53\tStep: 167200\tTraining-loss: 5.4764\tTest-loss: 5.5402\n",
            "Time: 25.53\tStep: 167400\tTraining-loss: 5.2747\tTest-loss: 5.3786\n",
            "Time: 25.53\tStep: 167600\tTraining-loss: 5.0782\tTest-loss: 5.1700\n",
            "Time: 25.53\tStep: 167800\tTraining-loss: 5.4339\tTest-loss: 5.4930\n",
            "Time: 25.53\tStep: 168000\tTraining-loss: 5.1576\tTest-loss: 5.2613\n",
            "Time: 25.53\tStep: 168200\tTraining-loss: 5.1160\tTest-loss: 5.2046\n",
            "Time: 25.53\tStep: 168400\tTraining-loss: 5.2766\tTest-loss: 5.3171\n",
            "Time: 25.53\tStep: 168600\tTraining-loss: 5.6500\tTest-loss: 5.6738\n",
            "Time: 25.53\tStep: 168800\tTraining-loss: 5.4888\tTest-loss: 5.6201\n",
            "Time: 25.47\tStep: 169000\tTraining-loss: 6.1190\tTest-loss: 6.1602\n",
            "Time: 25.53\tStep: 169200\tTraining-loss: 5.2077\tTest-loss: 5.2687\n",
            "Time: 25.53\tStep: 169400\tTraining-loss: 7.1447\tTest-loss: 7.1875\n",
            "Time: 25.53\tStep: 169600\tTraining-loss: 5.3575\tTest-loss: 5.3818\n",
            "Time: 25.52\tStep: 169800\tTraining-loss: 5.3100\tTest-loss: 5.4102\n",
            "Time: 25.54\tStep: 170000\tTraining-loss: 6.5264\tTest-loss: 6.7442\n",
            "Time: 25.53\tStep: 170200\tTraining-loss: 5.5876\tTest-loss: 5.6401\n",
            "Time: 25.54\tStep: 170400\tTraining-loss: 5.4301\tTest-loss: 5.4960\n",
            "Time: 25.52\tStep: 170600\tTraining-loss: 5.1316\tTest-loss: 5.2264\n",
            "Time: 25.53\tStep: 170800\tTraining-loss: 5.5450\tTest-loss: 5.6849\n",
            "Time: 25.53\tStep: 171000\tTraining-loss: 5.0496\tTest-loss: 5.1124\n",
            "Time: 25.54\tStep: 171200\tTraining-loss: 5.2235\tTest-loss: 5.2955\n",
            "Time: 25.53\tStep: 171400\tTraining-loss: 5.5088\tTest-loss: 5.6471\n",
            "Time: 25.48\tStep: 171600\tTraining-loss: 5.3212\tTest-loss: 5.3900\n",
            "Time: 25.52\tStep: 171800\tTraining-loss: 5.1535\tTest-loss: 5.2627\n",
            "Time: 25.53\tStep: 172000\tTraining-loss: 5.2376\tTest-loss: 5.3473\n",
            "Time: 25.53\tStep: 172200\tTraining-loss: 5.1934\tTest-loss: 5.2823\n",
            "Time: 25.53\tStep: 172400\tTraining-loss: 5.1478\tTest-loss: 5.2238\n",
            "Time: 25.53\tStep: 172600\tTraining-loss: 5.0941\tTest-loss: 5.1725\n",
            "Time: 25.53\tStep: 172800\tTraining-loss: 5.2758\tTest-loss: 5.3558\n",
            "Time: 25.53\tStep: 173000\tTraining-loss: 5.2636\tTest-loss: 5.3779\n",
            "Time: 25.55\tStep: 173200\tTraining-loss: 6.3476\tTest-loss: 6.3691\n",
            "Time: 25.53\tStep: 173400\tTraining-loss: 5.1162\tTest-loss: 5.1839\n",
            "Time: 25.53\tStep: 173600\tTraining-loss: 5.4646\tTest-loss: 5.5304\n",
            "Time: 25.53\tStep: 173800\tTraining-loss: 5.2641\tTest-loss: 5.3363\n",
            "Time: 25.47\tStep: 174000\tTraining-loss: 5.2659\tTest-loss: 5.3336\n",
            "Time: 25.53\tStep: 174200\tTraining-loss: 5.8852\tTest-loss: 5.9452\n",
            "Time: 25.53\tStep: 174400\tTraining-loss: 5.4197\tTest-loss: 5.5529\n",
            "Time: 25.53\tStep: 174600\tTraining-loss: 6.2579\tTest-loss: 6.4446\n",
            "Time: 25.54\tStep: 174800\tTraining-loss: 7.7314\tTest-loss: 7.9625\n",
            "Time: 25.52\tStep: 175000\tTraining-loss: 5.8802\tTest-loss: 5.9450\n",
            "Time: 25.54\tStep: 175200\tTraining-loss: 5.0375\tTest-loss: 5.1106\n",
            "Time: 25.53\tStep: 175400\tTraining-loss: 5.1594\tTest-loss: 5.2410\n",
            "Time: 25.53\tStep: 175600\tTraining-loss: 5.1478\tTest-loss: 5.2450\n",
            "Time: 25.53\tStep: 175800\tTraining-loss: 5.1941\tTest-loss: 5.2644\n",
            "Time: 25.52\tStep: 176000\tTraining-loss: 5.1390\tTest-loss: 5.1875\n",
            "Time: 25.53\tStep: 176200\tTraining-loss: 5.2154\tTest-loss: 5.3262\n",
            "Time: 25.48\tStep: 176400\tTraining-loss: 5.3614\tTest-loss: 5.4659\n",
            "Time: 25.53\tStep: 176600\tTraining-loss: 5.1126\tTest-loss: 5.2338\n",
            "Time: 25.53\tStep: 176800\tTraining-loss: 5.2344\tTest-loss: 5.3193\n",
            "Time: 25.53\tStep: 177000\tTraining-loss: 5.4461\tTest-loss: 5.4894\n",
            "Time: 25.54\tStep: 177200\tTraining-loss: 5.1646\tTest-loss: 5.2364\n",
            "Time: 25.53\tStep: 177400\tTraining-loss: 5.2108\tTest-loss: 5.2998\n",
            "Time: 25.53\tStep: 177600\tTraining-loss: 5.1390\tTest-loss: 5.1857\n",
            "Time: 25.53\tStep: 177800\tTraining-loss: 5.0919\tTest-loss: 5.1480\n",
            "Time: 25.53\tStep: 178000\tTraining-loss: 5.4766\tTest-loss: 5.5165\n",
            "Time: 25.53\tStep: 178200\tTraining-loss: 5.0841\tTest-loss: 5.1608\n",
            "Time: 25.53\tStep: 178400\tTraining-loss: 5.0484\tTest-loss: 5.0874\n",
            "Time: 25.53\tStep: 178600\tTraining-loss: 5.4491\tTest-loss: 5.5070\n",
            "Time: 25.46\tStep: 178800\tTraining-loss: 5.0312\tTest-loss: 5.1085\n",
            "Time: 25.53\tStep: 179000\tTraining-loss: 6.0782\tTest-loss: 6.1502\n",
            "Time: 25.54\tStep: 179200\tTraining-loss: 5.0934\tTest-loss: 5.1626\n",
            "Time: 25.54\tStep: 179400\tTraining-loss: 5.2598\tTest-loss: 5.3642\n",
            "Time: 25.53\tStep: 179600\tTraining-loss: 5.1199\tTest-loss: 5.2243\n",
            "Time: 25.53\tStep: 179800\tTraining-loss: 5.3501\tTest-loss: 5.4684\n",
            "Time: 25.53\tStep: 180000\tTraining-loss: 5.1626\tTest-loss: 5.2654\n",
            "Time: 25.53\tStep: 180200\tTraining-loss: 6.0516\tTest-loss: 6.1821\n",
            "Time: 25.52\tStep: 180400\tTraining-loss: 5.2148\tTest-loss: 5.3222\n",
            "Time: 25.53\tStep: 180600\tTraining-loss: 5.7339\tTest-loss: 5.7947\n",
            "Time: 25.53\tStep: 180800\tTraining-loss: 5.3163\tTest-loss: 5.4367\n",
            "Time: 25.54\tStep: 181000\tTraining-loss: 5.2990\tTest-loss: 5.3406\n",
            "Time: 25.53\tStep: 181200\tTraining-loss: 6.2279\tTest-loss: 6.2742\n",
            "Time: 25.48\tStep: 181400\tTraining-loss: 5.2266\tTest-loss: 5.3331\n",
            "Time: 25.53\tStep: 181600\tTraining-loss: 5.1965\tTest-loss: 5.2707\n",
            "Time: 25.53\tStep: 181800\tTraining-loss: 5.6873\tTest-loss: 5.7075\n",
            "Time: 25.53\tStep: 182000\tTraining-loss: 5.1883\tTest-loss: 5.2262\n",
            "Time: 25.53\tStep: 182200\tTraining-loss: 5.5431\tTest-loss: 5.6332\n",
            "Time: 25.53\tStep: 182400\tTraining-loss: 5.3772\tTest-loss: 5.5101\n",
            "Time: 25.54\tStep: 182600\tTraining-loss: 5.5192\tTest-loss: 5.6409\n",
            "Time: 25.53\tStep: 182800\tTraining-loss: 5.7996\tTest-loss: 5.8597\n",
            "Time: 25.53\tStep: 183000\tTraining-loss: 5.4864\tTest-loss: 5.5302\n",
            "Time: 25.53\tStep: 183200\tTraining-loss: 5.1084\tTest-loss: 5.2051\n",
            "Time: 25.54\tStep: 183400\tTraining-loss: 5.1918\tTest-loss: 5.2471\n",
            "Time: 25.53\tStep: 183600\tTraining-loss: 5.2416\tTest-loss: 5.2812\n",
            "Time: 25.48\tStep: 183800\tTraining-loss: 5.1388\tTest-loss: 5.2086\n",
            "Time: 25.53\tStep: 184000\tTraining-loss: 5.2388\tTest-loss: 5.3136\n",
            "Time: 25.54\tStep: 184200\tTraining-loss: 5.3407\tTest-loss: 5.4208\n",
            "Time: 25.54\tStep: 184400\tTraining-loss: 6.3318\tTest-loss: 6.3760\n",
            "Time: 25.53\tStep: 184600\tTraining-loss: 5.0642\tTest-loss: 5.1439\n",
            "Time: 25.53\tStep: 184800\tTraining-loss: 5.4351\tTest-loss: 5.5387\n",
            "Time: 25.53\tStep: 185000\tTraining-loss: 5.2355\tTest-loss: 5.3255\n",
            "Time: 25.53\tStep: 185200\tTraining-loss: 5.2940\tTest-loss: 5.3863\n",
            "Time: 25.54\tStep: 185400\tTraining-loss: 6.9584\tTest-loss: 6.9867\n",
            "Time: 25.53\tStep: 185600\tTraining-loss: 5.0873\tTest-loss: 5.1448\n",
            "Time: 25.54\tStep: 185800\tTraining-loss: 5.3056\tTest-loss: 5.4008\n",
            "Time: 25.52\tStep: 186000\tTraining-loss: 5.2079\tTest-loss: 5.3205\n",
            "Time: 25.47\tStep: 186200\tTraining-loss: 6.2496\tTest-loss: 6.3509\n",
            "Time: 25.53\tStep: 186400\tTraining-loss: 5.2691\tTest-loss: 5.3770\n",
            "Time: 25.53\tStep: 186600\tTraining-loss: 5.4688\tTest-loss: 5.5689\n",
            "Time: 25.53\tStep: 186800\tTraining-loss: 5.1502\tTest-loss: 5.2334\n",
            "Time: 25.53\tStep: 187000\tTraining-loss: 5.5793\tTest-loss: 5.6884\n",
            "Time: 25.53\tStep: 187200\tTraining-loss: 5.0565\tTest-loss: 5.1333\n",
            "Time: 25.54\tStep: 187400\tTraining-loss: 5.1269\tTest-loss: 5.1924\n",
            "Time: 25.53\tStep: 187600\tTraining-loss: 6.1281\tTest-loss: 6.3129\n",
            "Time: 25.53\tStep: 187800\tTraining-loss: 5.4841\tTest-loss: 5.5110\n",
            "Time: 25.53\tStep: 188000\tTraining-loss: 5.1178\tTest-loss: 5.1846\n",
            "Time: 25.53\tStep: 188200\tTraining-loss: 6.0160\tTest-loss: 6.0714\n",
            "Time: 25.53\tStep: 188400\tTraining-loss: 5.1627\tTest-loss: 5.2140\n",
            "Time: 25.47\tStep: 188600\tTraining-loss: 5.4743\tTest-loss: 5.5941\n",
            "Time: 25.53\tStep: 188800\tTraining-loss: 5.5474\tTest-loss: 5.5982\n",
            "Time: 25.53\tStep: 189000\tTraining-loss: 6.6051\tTest-loss: 6.7829\n",
            "Time: 25.53\tStep: 189200\tTraining-loss: 4.9620\tTest-loss: 5.0404\n",
            "Time: 25.54\tStep: 189400\tTraining-loss: 5.0538\tTest-loss: 5.1334\n",
            "Time: 25.53\tStep: 189600\tTraining-loss: 5.5441\tTest-loss: 5.5574\n",
            "Time: 25.53\tStep: 189800\tTraining-loss: 5.4685\tTest-loss: 5.6019\n",
            "Time: 25.53\tStep: 190000\tTraining-loss: 5.6521\tTest-loss: 5.7171\n",
            "Time: 25.53\tStep: 190200\tTraining-loss: 5.4450\tTest-loss: 5.4969\n",
            "Time: 25.54\tStep: 190400\tTraining-loss: 5.0484\tTest-loss: 5.1322\n",
            "Time: 25.53\tStep: 190600\tTraining-loss: 5.3745\tTest-loss: 5.4667\n",
            "Time: 25.53\tStep: 190800\tTraining-loss: 5.0914\tTest-loss: 5.1781\n",
            "Time: 25.53\tStep: 191000\tTraining-loss: 5.5713\tTest-loss: 5.7134\n",
            "Time: 25.48\tStep: 191200\tTraining-loss: 5.9689\tTest-loss: 6.1301\n",
            "Time: 25.53\tStep: 191400\tTraining-loss: 5.9668\tTest-loss: 5.9791\n",
            "Time: 25.53\tStep: 191600\tTraining-loss: 5.1929\tTest-loss: 5.2570\n",
            "Time: 25.53\tStep: 191800\tTraining-loss: 5.1819\tTest-loss: 5.2732\n",
            "Time: 25.55\tStep: 192000\tTraining-loss: 5.3484\tTest-loss: 5.4460\n",
            "Time: 25.53\tStep: 192200\tTraining-loss: 5.7470\tTest-loss: 5.7895\n",
            "Time: 25.53\tStep: 192400\tTraining-loss: 6.0850\tTest-loss: 6.2334\n",
            "Time: 25.53\tStep: 192600\tTraining-loss: 5.0578\tTest-loss: 5.1367\n",
            "Time: 25.53\tStep: 192800\tTraining-loss: 5.3731\tTest-loss: 5.4054\n",
            "Time: 25.53\tStep: 193000\tTraining-loss: 5.1221\tTest-loss: 5.2140\n",
            "Time: 25.53\tStep: 193200\tTraining-loss: 5.0697\tTest-loss: 5.1568\n",
            "Time: 25.53\tStep: 193400\tTraining-loss: 5.2103\tTest-loss: 5.3277\n",
            "Time: 25.50\tStep: 193600\tTraining-loss: 5.2052\tTest-loss: 5.3100\n",
            "Time: 25.55\tStep: 193800\tTraining-loss: 5.0864\tTest-loss: 5.1611\n",
            "Time: 25.55\tStep: 194000\tTraining-loss: 5.1088\tTest-loss: 5.1697\n",
            "Time: 25.55\tStep: 194200\tTraining-loss: 5.5774\tTest-loss: 5.6148\n",
            "Time: 25.53\tStep: 194400\tTraining-loss: 5.1492\tTest-loss: 5.1808\n",
            "Time: 25.53\tStep: 194600\tTraining-loss: 5.0815\tTest-loss: 5.1758\n",
            "Time: 25.53\tStep: 194800\tTraining-loss: 5.1164\tTest-loss: 5.2174\n",
            "Time: 25.53\tStep: 195000\tTraining-loss: 5.4871\tTest-loss: 5.5495\n",
            "Time: 25.54\tStep: 195200\tTraining-loss: 5.4550\tTest-loss: 5.5056\n",
            "Time: 25.53\tStep: 195400\tTraining-loss: 5.2059\tTest-loss: 5.2930\n",
            "Time: 25.54\tStep: 195600\tTraining-loss: 5.1252\tTest-loss: 5.2075\n",
            "Time: 25.53\tStep: 195800\tTraining-loss: 5.1619\tTest-loss: 5.2799\n",
            "Time: 25.47\tStep: 196000\tTraining-loss: 5.2607\tTest-loss: 5.3735\n",
            "Time: 25.53\tStep: 196200\tTraining-loss: 5.2181\tTest-loss: 5.3010\n",
            "Time: 25.53\tStep: 196400\tTraining-loss: 5.0451\tTest-loss: 5.1141\n",
            "Time: 25.53\tStep: 196600\tTraining-loss: 5.3023\tTest-loss: 5.3629\n",
            "Time: 25.54\tStep: 196800\tTraining-loss: 5.2002\tTest-loss: 5.2696\n",
            "Time: 25.54\tStep: 197000\tTraining-loss: 5.0049\tTest-loss: 5.0681\n",
            "Time: 25.54\tStep: 197200\tTraining-loss: 5.3224\tTest-loss: 5.4208\n",
            "Time: 25.53\tStep: 197400\tTraining-loss: 5.4559\tTest-loss: 5.5191\n",
            "Time: 25.55\tStep: 197600\tTraining-loss: 5.2488\tTest-loss: 5.2889\n",
            "Time: 25.54\tStep: 197800\tTraining-loss: 5.6446\tTest-loss: 5.7494\n",
            "Time: 25.54\tStep: 198000\tTraining-loss: 5.2371\tTest-loss: 5.2957\n",
            "Time: 25.54\tStep: 198200\tTraining-loss: 5.3821\tTest-loss: 5.4103\n",
            "Time: 25.48\tStep: 198400\tTraining-loss: 5.3717\tTest-loss: 5.3952\n",
            "Time: 25.54\tStep: 198600\tTraining-loss: 5.1142\tTest-loss: 5.1421\n",
            "Time: 25.53\tStep: 198800\tTraining-loss: 5.0600\tTest-loss: 5.1272\n",
            "Time: 25.53\tStep: 199000\tTraining-loss: 5.1102\tTest-loss: 5.1906\n",
            "Time: 25.53\tStep: 199200\tTraining-loss: 5.1878\tTest-loss: 5.2235\n",
            "Time: 25.53\tStep: 199400\tTraining-loss: 5.0884\tTest-loss: 5.1498\n",
            "Time: 25.54\tStep: 199600\tTraining-loss: 5.7140\tTest-loss: 5.7316\n",
            "Time: 25.53\tStep: 199800\tTraining-loss: 5.3953\tTest-loss: 5.4238\n",
            "Time: 25.53\tStep: 200000\tTraining-loss: 5.2146\tTest-loss: 5.2540\n",
            "Time: 25.53\tStep: 200200\tTraining-loss: 5.1072\tTest-loss: 5.1995\n",
            "Time: 25.53\tStep: 200400\tTraining-loss: 5.5238\tTest-loss: 5.5855\n",
            "Time: 25.53\tStep: 200600\tTraining-loss: 5.0389\tTest-loss: 5.1269\n",
            "Time: 25.53\tStep: 200800\tTraining-loss: 5.0799\tTest-loss: 5.1655\n",
            "Time: 25.47\tStep: 201000\tTraining-loss: 5.8714\tTest-loss: 5.9561\n",
            "Time: 25.53\tStep: 201200\tTraining-loss: 5.7757\tTest-loss: 5.7971\n",
            "Time: 25.55\tStep: 201400\tTraining-loss: 6.2832\tTest-loss: 6.4485\n",
            "Time: 25.53\tStep: 201600\tTraining-loss: 5.0353\tTest-loss: 5.0855\n",
            "Time: 25.53\tStep: 201800\tTraining-loss: 5.4351\tTest-loss: 5.4691\n",
            "Time: 25.53\tStep: 202000\tTraining-loss: 5.1546\tTest-loss: 5.2152\n",
            "Time: 25.53\tStep: 202200\tTraining-loss: 5.4018\tTest-loss: 5.4504\n",
            "Time: 25.53\tStep: 202400\tTraining-loss: 5.2241\tTest-loss: 5.2995\n",
            "Time: 25.53\tStep: 202600\tTraining-loss: 5.0204\tTest-loss: 5.0973\n",
            "Time: 25.53\tStep: 202800\tTraining-loss: 5.1337\tTest-loss: 5.1775\n",
            "Time: 25.54\tStep: 203000\tTraining-loss: 5.1345\tTest-loss: 5.2009\n",
            "Time: 25.53\tStep: 203200\tTraining-loss: 5.2666\tTest-loss: 5.3301\n",
            "Time: 25.47\tStep: 203400\tTraining-loss: 5.7440\tTest-loss: 5.8254\n",
            "Time: 25.53\tStep: 203600\tTraining-loss: 5.1832\tTest-loss: 5.2692\n",
            "Time: 25.54\tStep: 203800\tTraining-loss: 5.1025\tTest-loss: 5.1594\n",
            "Time: 25.54\tStep: 204000\tTraining-loss: 5.1625\tTest-loss: 5.2376\n",
            "Time: 25.53\tStep: 204200\tTraining-loss: 5.2449\tTest-loss: 5.3322\n",
            "Time: 25.53\tStep: 204400\tTraining-loss: 5.1759\tTest-loss: 5.2067\n",
            "Time: 25.54\tStep: 204600\tTraining-loss: 5.0723\tTest-loss: 5.0974\n",
            "Time: 25.53\tStep: 204800\tTraining-loss: 5.6563\tTest-loss: 5.6632\n",
            "Time: 25.53\tStep: 205000\tTraining-loss: 6.2074\tTest-loss: 6.2407\n",
            "Time: 25.53\tStep: 205200\tTraining-loss: 5.0474\tTest-loss: 5.0838\n",
            "Time: 25.53\tStep: 205400\tTraining-loss: 5.0306\tTest-loss: 5.0711\n",
            "Time: 25.53\tStep: 205600\tTraining-loss: 5.1773\tTest-loss: 5.1881\n",
            "Time: 25.48\tStep: 205800\tTraining-loss: 5.1444\tTest-loss: 5.1936\n",
            "Time: 25.53\tStep: 206000\tTraining-loss: 5.1214\tTest-loss: 5.1636\n",
            "Time: 25.55\tStep: 206200\tTraining-loss: 5.4191\tTest-loss: 5.4987\n",
            "Time: 25.53\tStep: 206400\tTraining-loss: 5.3967\tTest-loss: 5.4702\n",
            "Time: 25.53\tStep: 206600\tTraining-loss: 5.0296\tTest-loss: 5.0672\n",
            "Time: 25.53\tStep: 206800\tTraining-loss: 5.0868\tTest-loss: 5.1464\n",
            "Time: 25.53\tStep: 207000\tTraining-loss: 6.8659\tTest-loss: 6.8774\n",
            "Time: 25.53\tStep: 207200\tTraining-loss: 5.0686\tTest-loss: 5.1179\n",
            "Time: 25.53\tStep: 207400\tTraining-loss: 5.2732\tTest-loss: 5.3213\n",
            "Time: 25.53\tStep: 207600\tTraining-loss: 5.2347\tTest-loss: 5.2717\n",
            "Time: 25.54\tStep: 207800\tTraining-loss: 5.3259\tTest-loss: 5.3258\n",
            "Time: 25.53\tStep: 208000\tTraining-loss: 5.4157\tTest-loss: 5.4795\n",
            "Time: 25.47\tStep: 208200\tTraining-loss: 5.0829\tTest-loss: 5.1090\n",
            "Time: 25.53\tStep: 208400\tTraining-loss: 6.5668\tTest-loss: 6.5927\n",
            "Time: 25.53\tStep: 208600\tTraining-loss: 5.7054\tTest-loss: 5.7229\n",
            "Time: 25.53\tStep: 208800\tTraining-loss: 5.3474\tTest-loss: 5.3502\n",
            "Time: 25.53\tStep: 209000\tTraining-loss: 5.6688\tTest-loss: 5.6804\n",
            "Time: 25.53\tStep: 209200\tTraining-loss: 5.7962\tTest-loss: 5.8172\n",
            "Time: 25.53\tStep: 209400\tTraining-loss: 5.0332\tTest-loss: 5.0642\n",
            "Time: 25.53\tStep: 209600\tTraining-loss: 6.2229\tTest-loss: 6.2432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Hh4UaaDhQh"
      },
      "source": [
        "Now that we've trained the network, we can define a neural network energy that we can use in simulations using a single line. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFu7WSabEU2m"
      },
      "source": [
        "neural_energy_fun = lambda positions: vectorized_energy(best_params, positions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qKO-hotEUT8"
      },
      "source": [
        "We can plot the losses during training as well as the predicted energies against the ground truth energies on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea5MKx65cMDO"
      },
      "source": [
        "### Preliminary results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUpe-N7PAQQ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "f65f17ca-c274-4c44-c3a1-19ae7098fb45"
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "out_steps = [x * print_every for x in range(len(train_losses))]\n",
        "plt.plot(out_steps[:], train_losses[:], linewidth=3, label='Training loss')\n",
        "plt.plot(out_steps[:], test_losses[:], linewidth=3, label='Test loss', linestyle='--')\n",
        "plt.axhline(min_loss, linestyle='--', color='C0', label='Best loss on train')\n",
        "\n",
        "plt.legend(loc='lower right')\n",
        "format_plot('Step', 'Loss')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "\n",
        "\n",
        "plt.plot(test_energies, neural_energy_fun(test_positions), 'o')\n",
        "plt.plot(test_energies, test_energies, 'r--', linewidth=3)\n",
        "plt.xlabel('Correct energy', fontsize=20)\n",
        "plt.ylabel('Predicted energy', fontsize=20)\n",
        "\n",
        "#plt.xlim([1.9, 3.0])\n",
        "\n",
        "finalize_plot((2, 0.75))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x324 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_ZQlKRdRuy7"
      },
      "source": [
        "Let's provide some preliminary data for comparison. In one of the baseline notebooks, [Neural network potentials](https://colab.research.google.com/github/google/jax-md/blob/master/notebooks/neural_networks.ipynb#scrollTo=WNs8v2745Mc3) the final prediction is made by a Graph Network, which was trained for 12k epochs. As you can see, with new descriptors we arrive at test RMSE only around 3 times larger in ~300 epochs. Adding more epochs doesn't seem to improve the result, next step is to\n",
        "\n",
        "1.   Experiment with the optimizer\n",
        "2.   Enrich the feature description by enlarging `k_max`, `l_max` (right now we have `k_max = 5`, `l_max = 5`, which results in 55 total descriptors). This is (at least for now) time-consuming due to lack of sph_harm in JAX (explained above)\n",
        "3.   Enrich the feature description by adding new RI features (this will take more reading papers and coding)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn8OeWIORfCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54cecb3d-6531-4f92-cecd-22cc2d60d323"
      },
      "source": [
        "print(\"Baseline RMSE Error (on test) is 3 meV / atom\") # copypasted from baseline notebook\n",
        "n_atoms = train_positions.shape[1]\n",
        "energy_rmse = np.sqrt(\n",
        "    np.mean(\n",
        "        (neural_energy_fun(test_positions) - test_energies)**2))\n",
        "final_loss_mev_atom = energy_rmse*1000/n_atoms\n",
        "print(f\"RMSE Error (on test)          is {final_loss_mev_atom:.2f} mev / atom\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline RMSE Error (on test) is 3 meV / atom\n",
            "RMSE Error (on test)          is 26.35 mev / atom\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09NSNarnOZ6_"
      },
      "source": [
        "## (Old) Radial symmetry descriptors\n",
        "I'll use the same methodology as in the [JAX-MD cookbook](https://colab.research.google.com/github/google/jax-md/blob/master/notebooks/jax_md_cookbook.ipynb#scrollTo=WRD2t3GVPMpn) but on the dataset from [Neural network potentials notebook](https://colab.research.google.com/github/google/jax-md/blob/master/notebooks/neural_networks.ipynb#scrollTo=WNs8v2745Mc3) (potential there seems to be dependent on angles)"
      ]
    }
  ]
}